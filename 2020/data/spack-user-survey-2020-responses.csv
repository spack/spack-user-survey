Timestamp,What kind of user are you?,Where do you work?,What country are you in?,Are you part of the U.S. Exascale Computing Project (ECP)?,What are your primary application areas?,How did you find out about Spack?,How long have you been using Spack?,Have you contributed to Spack?,What version(s) of Spack do you use?,What OS do you use Spack on?,How many software installations have you done with Spack in the past year?,What Python version(s) do you use to run Spack?,How bad would it be if Spack dropped support for Python 2.6?,How bad would it be if Spack ONLY worked with Python 3?,How do you get installed Spack packages into your environment?,Which of the following Spack features do you use?,Which processors do you expect to use with Spack in the next year?,Which GPUs do you expect to use with Spack in the next year?,Which compilers do you expect to use with Spack in the next year?,"Rank these TBD Spack features by importance [New, backtracking concretizer]",Rank these TBD Spack features by importance [Use existing installs more aggressively],Rank these TBD Spack features by importance [Separate concretization of build dependencies ],Rank these TBD Spack features by importance [AWS/Azure/GCP/Cloud integration],"Rank these TBD Spack features by importance [Optimized, public binary packages]",Rank these TBD Spack features by importance [Better Developer features (easily develop multiple packages + 3rd party dependencies)],Rank these TBD Spack features by importance [Notifications about changes to my packages],Rank these TBD Spack features by importance [Build testing for every PR],"Rank these TBD Spack features by importance [Language virtual dependencies (e.g., depends_on(""cxx@2017:""))]",Rank these TBD Spack features by importance [Testing / integration with Pavilion2/ReFrame/other test tool],Rank these TBD Spack features by importance [Better compiler flag handling],Rank these TBD Spack features by importance [Windows Support],What features NOT in the prior list would you like to see?,"If we had a (virtual) workshop on Spack, would you attend? ",Have you done a Spack Tutorial?,How do you get help with Spack when you need it?,How often do you consult the Spack documentation?,"If there were commercial support for Spack, would you or your organization buy it?",How would you rate the overall quality of ... [Spack documentation],How would you rate the overall quality of ... [Spack community],How would you rate the overall quality of ... [Spack packages],How would you rate the overall quality of ... [Spack],Tell us briefly about your use case and your usual Spack workflow.,What about Spack helps you the most?,What are the biggest pain points in Spack for your workflow? (feel free to link to issues),What's the biggest thing we could do to improve Spack over the next year?,Are there key packages you'd like to see in Spack that are not included yet?,Do you have any other comments for us?
11/17/2020 18:23:58,Software Developer,University HPC/Computing Center,United Kingdom,No,Traditional HPC / Simulation,Word of mouth,0,"Packages, Slack Discussions",develop,"macOS, Red Hat, Ubuntu",10 - 100,"3.6, 3.7, 3.8",Do it!,Do it!,"spack load, Spack environments, Environment Modules (TCL modules)",Environments,"AMD, Intel, ARM",NVIDIA,"gcc, Intel Compilers, Intel OneAPI / dpc++, LLVM, nvcc",Not Important,Slightly Important,Somewhat important,Not Important,Slightly Important,Somewhat important,Slightly Important,Somewhat important,Not Important,Somewhat important,Slightly Important,Not Important,,Maybe,No,"Documentation, Slack, Coworkers",Monthly,Probably not,OK,Good,OK,OK,installing a specific package on HPC,"when it works, it is great to just be able to sit back and let it build",when it fails unpredictably midway through a long build,fix broken packages,moose,
11/17/2020 18:24:44,Software Developer,Company,United Kingdom,No,Traditional HPC / Simulation,Word of mouth,0,No,0.14,"Red Hat, Ubuntu",10 - 100,"3.6, 3.7, 3.8",Do it!,Do it!,spack load,"Binary Caches, spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml","Intel, ARM",NVIDIA,"gcc, armclang",Somewhat important,Very Important,Very Important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Very Important,Somewhat important,Somewhat important,Very Important,Not Important,Support for substitution of common libs like FFTW for vendor-supplied equivalent maths libs.,Maybe,Yes,"Documentation, Coworkers",Monthly,Probably not,Bad,OK,Bad,Bad,,,,,,
11/17/2020 18:25:24,Scientist/Researcher,Other Public Research Lab,France,No,Traditional HPC / Simulation,Word of mouth,1,Packages,"0.15, develop","CentOS, Ubuntu, Debian, Arch",10 - 100,"3.7, 3.8",Do it!,Do it!,spack load,"Module generation, build-env (debug a build)","AMD, Intel",NVIDIA,gcc,Very Important,Somewhat important,Slightly Important,Not Important,Not Important,Critical,Very Important,Somewhat important,Somewhat important,Not Important,Somewhat important,Not Important,,"Yes, I'd attend",Yes,"Documentation, Slack",Monthly,Probably not,Good,Good,Good,Excellent,I am using spack to install dependencies before working on my own sofware,Install correct dependencies ,package/sofware development is not so straightforward,better developer functionalities,,
11/17/2020 18:26:08,Software Developer,Other Public Research Lab,Switzerland,No,Traditional HPC / Simulation,Word of mouth,1,Packages,develop,"CentOS, Arch",200 - 500,3.8,Do it!,Do it!,"spack load, Spack environments","Environments, build-env (debug a build)","AMD, Intel","NVIDIA, AMD","gcc, LLVM, AMD aocc, AMD hipclang, nvcc, CCE (Cray Compilers)",Very Important,Very Important,Somewhat important,Not Important,Somewhat important,Very Important,Slightly Important,Very Important,Somewhat important,Slightly Important,Slightly Important,Not Important,,"Yes, I'd attend",Yes,"Documentation, Slack, Coworkers",Weekly,Probably not,Good,Good,Good,Good,,,,,,
11/17/2020 18:27:33,Software Developer,Other Public Research Lab,Japan,No,Traditional HPC / Simulation,Used at my site,5,Packages,develop,"Red Hat, CentOS",100 - 200,"2.7, 3.5, 3.6",Do it!,Do it!,spack load,"Chaining, Stacks (matrices in environments), Command Extensions","Intel, ARM",NVIDIA,"gcc, LLVM, Fujitsu Compilers, armclang",Very Important,Very Important,Very Important,Very Important,Very Important,Very Important,Very Important,Very Important,Very Important,Very Important,Very Important,Very Important,,"Yes, I'd attend",No,Slack,Weekly,Probably not,Excellent,Excellent,Excellent,Excellent,,,,,,
11/17/2020 18:28:51,System Administrator,Other Public Research Lab,Japan,No,"Traditional HPC / Simulation, Computer Science Research",Tutorial,1,"Packages, Core Features, Slack Discussions",develop,"Red Hat, CentOS","> 1,000",3.6,I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),spack load,"Chaining, spack external find, Distributed Builds (srun spack install)","Intel, ARM",NVIDIA,"gcc, Fujitsu Compilers, armclang",Very Important,Somewhat important,Slightly Important,Not Important,Slightly Important,Somewhat important,Somewhat important,Very Important,Very Important,Somewhat important,Somewhat important,Not Important,cross build,Maybe,Yes,"Documentation, Slack",Daily,Probably not,Good,Excellent,Excellent,Excellent,,,,,,
11/17/2020 18:30:34,Software Developer,University HPC/Computing Center,Switzerland,No,Traditional HPC / Simulation,Word of mouth,1,No,develop,"macOS, Red Hat, Ubuntu",1 - 10,"3.7, 3.8",Do it!,Do it!,"spack load, Spack environments","Environments, Module generation, Distributed Builds (srun spack install)","AMD, Intel","NVIDIA, AMD","gcc, AMD aocc, AMD hipclang, nvcc",Somewhat important,Very Important,Somewhat important,Slightly Important,Slightly Important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Not Important,,Maybe,No,"Documentation, Slack, Coworkers",Monthly,Probably not,Good,Good,Good,Good,,,,,,
11/17/2020 18:32:43,Software Developer,University HPC/Computing Center,Switzerland,No,Traditional HPC / Simulation,Word of mouth,2,"Packages, Slack Discussions, Issues","0.13, 0.15","Red Hat, Ubuntu","> 1,000",3.5,Do it!,Do it!,"spack load, Spack environments, Environment Modules (TCL modules)","Environments, Module generation, Chaining, Stacks (matrices in environments), Binary Caches, build-env (debug a build), spack-python (Python scripting), Externals in packages.yaml, Concretization preferences in packages.yaml, Distributed Builds (srun spack install)",Intel,NVIDIA,"gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), LLVM",Very Important,Very Important,Very Important,Not Important,Not Important,Very Important,Not Important,Slightly Important,Slightly Important,Slightly Important,Slightly Important,Not Important,JUnit reports,"Yes, I'd present something!",No,"Documentation, Slack, Coworkers",Weekly,Probably not,Good,Good,Good,Good,"As a developer, lots of dev-build and building in environments, deleting installs, playing around with variants. As the responsible one for software deployment, I customize our branch of Spack quite a bit to help deploy several hundred software packages in a continuous deployment using chains (and environments in the future). Currently, a full deployment from scratch takes about 24h, adding a single package ~20m.","Absolute flexibility, especially compared to, i.e., nix. And dependency handling, which I never want to do manually again.","Right now, the time it takes to concretize in our deployment with ~2000 packages already in the database.","Faster concretization, preferably in a stable release. Resource handling that allows for different source downloads depending on the variants.",,
11/17/2020 18:34:48,Software Developer,Company,France,No,Computer Science Research,Word of mouth,1,"Packages, Documentation, Slack Discussions",0.15,"CentOS, Ubuntu",100 - 200,2.7,Do it!,Do it!,"Spack environments, Environment Modules (TCL modules)","Environments, Module generation, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,gcc,Slightly Important,Somewhat important,Somewhat important,Not Important,Not Important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Not Important,Slightly Important,Not Important,more documentation about python packaging (in a virtual env),"Yes, I'd attend",Yes,"Documentation, Coworkers",Daily,Probably not,Good,Good,Good,Good,"I'm using Spack to be able to install my project (a python package) with other Spack packages from my company. But I want to be able to still use «pip».
About the workflow, I'm following my coworkers.",Installing Qt and PySide2 (except the WebEngine),Accents and utf-8 in recipes (in package.py),"Improving some messages such as «==> Updating view at /nfs2/mdorier/spack/var/spack/environments/colza-env/.spack-env/view
==> Error: the transactional move of ""/.../myenv/.spack-env/view"" failed.»",,
11/17/2020 18:36:29,Software Developer,University HPC/Computing Center,Singapore,No,"Traditional HPC / Simulation, AI/ML, Bioinformatics",Word of mouth,0,No,0.15,"CentOS, Fedora",1 - 10,"3.7, 3.8",I'd live.  (I can provide 2.7 somehow),Do it!,"spack load, Lmod, Environment Modules (TCL modules)","Environments, Externals in packages.yaml","AMD, Intel, ARM",NVIDIA,"gcc, Intel Compilers, AMD aocc, nvcc, CCE (Cray Compilers)",Slightly Important,Somewhat important,Critical,Somewhat important,Critical,Very Important,Very Important,Somewhat important,Somewhat important,Not Important,Somewhat important,Not Important,"May be towards ease of production deployment and updates. More stringent test and choice on the dependency package versions to ensure at least a success build, not to say completing regression tests of the applications.","Yes, I'd attend",No,"Documentation, Slack, Mailing List",Daily,Probably not,OK,Excellent,OK,OK,Still at explore stage to resolve HPC software build and management issues. Build multiple versions for HPC benchmarking. Spack could be used to learn how to build new applications.,Easily build different application versions.,"After waiting for hours for an install, and fail at the last stage due to incompatible library versions e.g. linking errors, where these could have been avoided if the official choice of library versions have been used.","More stringent dependent library versions controlled rather than leaving open ended for many. We know that from experience, no software can forever work with all future dependent library versions.",WRF. I'm aware that it's now included in develop branch.,Great work and great community. I wish to take part in the near future.
11/17/2020 18:37:59,System Administrator,University HPC/Computing Center,United Kingdom,No,Traditional HPC / Simulation,Word of mouth,1,No,0.15,CentOS,1 - 10,"2.7, 3.6",I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),"spack load, Spack environments, Environment Modules (TCL modules)","Environments, Module generation, Externals in packages.yaml","AMD, Intel","NVIDIA, AMD","gcc, Intel Compilers, Intel OneAPI / dpc++, AMD aocc",Somewhat important,Very Important,Somewhat important,Not Important,Not Important,Slightly Important,Slightly Important,Slightly Important,Slightly Important,Not Important,Slightly Important,Not Important,"Better support for system-wide installs, and documentation/recipes how to do this.","Yes, I'd attend",Yes,Documentation,Weekly,Probably not,Bad,OK,Good,OK,"Installing a spack stack system wide for developers to use, with different optimisations for different cpu architectures",Simplification of install procedure.,Spack on NFS doesn't seem to work well (e.g. permission denied for perfectly readable files).  Failures to concretize with nonsense errors.,"Recipes for installing system wide, using existing compilers, on different architectures",,
11/17/2020 18:39:25,Scientist/Researcher,Other Public Research Lab,Hungary,No,"Traditional HPC / Simulation, Bioinformatics",Word of mouth,2,"Packages, Issues",develop,Arch,100 - 200,"3.6, 3.7, 3.8",Do it!,Do it!,"spack load, Spack environments",Environments,"AMD, Intel",NVIDIA,"gcc, Intel Compilers, LLVM",Somewhat important,Somewhat important,Somewhat important,Not Important,Not Important,Critical,Critical,Not Important,Very Important,Slightly Important,Somewhat important,Not Important,,Maybe,No,"Documentation, Mailing List",Monthly,Probably not,Excellent,Excellent,Excellent,Excellent,"I manage a small cluster (5 computers, including the head node, 3 different architectures: linux-archrolling-zen, linux-archrolling-skylake, linux-archrolling-nehalem; each node has a GPU: NVidia GTX 1080 Ti or NVidia GTX 1050 Ti). We use several versions of GROMACS and PLUMED. I have one spack environment for each arch, containing all the packages. The slurm prolog script ensures that the appropriate environment is loaded from the job script, and then ""spack load"" can load the appropriate modules.","Automating builds and dependencies, managing several versions of software. ",Lack of support for inhomogeneous clusters.,"More support for inhomogeneous clusters: 1) make ""spack load"" recognize the architecture it runs on and take only packages built for that architecture (or a more general one, e.g. on sandybridge, use sandybridge or x86_64. 2) Make include directives work in all configuration YAML files, in all sections. This way one can have a spack environment corresponding to each target, and the environment spack.yaml files can have the same requirement sections.",,Keep up the good work!
11/17/2020 18:43:06,Software Developer,Other Public Research Lab,Italy,No,"Traditional HPC / Simulation, Compiler Testing",Word of mouth,5,"Packages, Core Features, Slack Discussions, Issues",develop,"macOS, Red Hat, Ubuntu",100 - 200,2.7,Do it!,Unacceptable,Environment Modules (TCL modules),"Environments, Module generation, build-env (debug a build), Externals in packages.yaml, Concretization preferences in packages.yaml","Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel OneAPI / dpc++, LLVM, nvcc, Fujitsu Compilers, armclang",Very Important,Somewhat important,Slightly Important,Not Important,Very Important,Somewhat important,Somewhat important,Critical,Somewhat important,Not Important,Somewhat important,Not Important,"QA, e.g.: more extensive CI on packages for tagged releases.","Yes, I'd attend",Yes,"Documentation, GitHub",Weekly,Probably,Excellent,Excellent,Good,Good,,,,"QA: less features but really solid CI on tagged releases, including packages.",,"It would be great to be able to offer GitHub CI runners on local HPC machines to test weird packages/variants that are hard to test otherwise (e.g.: vendor's math libraries, vendor's toolchains, etc...)."
11/17/2020 22:07:20,Scientist/Researcher,Other Public Research Lab,Germany,No,Traditional HPC / Simulation,Word of mouth,0,No,0.14,Red Hat,10 - 100,3.7,Do it!,Do it!,"spack load, Environment Modules (TCL modules)","Environments, Module generation","Intel, IBM Power",NVIDIA,"gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), CCE (Cray Compilers)",Very Important,Very Important,Very Important,Somewhat important,Very Important,Somewhat important,Very Important,Very Important,Somewhat important,Somewhat important,Very Important,Somewhat important,,Maybe,Yes,Documentation,Monthly,Probably not,Good,Excellent,Good,Excellent,Building application dependencies for 2nd class compilers on HPC (e.g. hdf5-mpi w/ pgi on power9 system),combinatorial build options.,,,,
11/17/2020 18:48:53,Software Developer,University HPC/Computing Center,Switzerland,No,Traditional HPC / Simulation,Used at my site,1,"Packages, Issues",develop,"CentOS, Arch",10 - 100,"3.6, 3.8",Do it!,Do it!,spack build-env,"Environments, Module generation, build-env (debug a build), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power","NVIDIA, AMD, Intel","gcc, NVIDIA Compilers (new PGI), LLVM, AMD hipclang, nvcc",Very Important,Critical,Very Important,Somewhat important,Critical,Critical,Somewhat important,Very Important,Very Important,Somewhat important,Somewhat important,Somewhat important,"1. Public binary mirror
2. Better handling of package components (a mechanism different than variant() that builds on top of the base package instead of reinstalling everything)
3. Breaking up big and commonly used packages such as Boost and Trilinos into separate smaller packages when possible. (this is related to 1. as this will prevent reinstalling unrelated components and internal dependencies)
4. Document that `variant()` should only be used for options that change the final binary output of a recipe. (e.g. intel-mkl and intel-parallel-studio do NOT follow this rule, but I think they should as they include all the variant combinations already)
5. Better reusability of installed packages which takes account of ABI and build types: if a package is a C library, it is likely ABI compatible between compilers (e.g. gcc or clang) and between different versions of the same compiler, it is often not necessary to rebuild it with a newer compiler. Also it doesn't matter much if the build tool used (e.g. cmake) has a matching compiler in the spec that is being installed. ","Yes, I'd attend",Yes,"Documentation, Slack, Coworkers",Weekly,Probably,Good,Excellent,Excellent,Good,"I am a software developer. There is a spack recipe in the repository of the project I am working on (https://github.com/eth-cscs/DLA-Future). The spack package is slightly tweeked to match the branch I am currently working on. For each branch, I install a different version of the package and then use `spack build-env --dump <file> <spec>; source <file>` to get an environment that allows me to build and test the code as I work on the branch.",The concretizer (despite some issues) is the most helpful aspect of Spack. It allows for automatic dependency management and reproducibility.,"1. Handling of clang as a CUDA compiler (not as a host compiler for nvcc but for actually compiling CUDA code: the issue is in constraints specified in spack/lib/spack/spack/build_systems/cuda.py)
2. Dealing with huge packages such as Boost and Trilinos that often cause lengthy reinstalls due to their myriad variants. (it would be nice to break them up into smaller packages if possible)
3. Concretizer quirks around ABI and built types which cause lengthy reinstalls. Currently, to circumvent some of that, I've added most build tools and some system C libraries to my `package.py` marking them as `buildable: false`.
4. It would be nice if `spack dev-build` allowed for a custom build directory to be specified",public binary mirror,,
11/17/2020 18:50:20,Software Developer,Company,India,No,Traditional HPC / Simulation,Word of mouth,0,Packages,0.15,"Red Hat, CentOS",100 - 200,"3.5, 3.6, 3.7, 3.8",Do it!,I'd live (I can provide Python 3 somehow),"spack load, Spack environments","Environments, spack containerize, build-env (debug a build)","AMD, Intel",NVIDIA,"gcc, Intel Compilers, Intel OneAPI / dpc++, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc",Critical,Very Important,Critical,Critical,Critical,Critical,Critical,Very Important,Critical,Critical,Critical,Somewhat important,profiling tools,"Yes, I'd present something!",No,"Documentation, Slack",Daily,Probably,OK,Excellent,Excellent,Excellent,building HPC apps with different toolchains,building applications quickly and simply,Spack discussions over github are huge text and no conclusion provided,Providing AI and Cloud support,,
11/17/2020 18:51:53,Scientist/Researcher,University HPC/Computing Center,Japan,No,Traditional HPC / Simulation,Used at my site,1,No,0.15,CentOS,10 - 100,2.7,I'd live.  (I can provide 2.7 somehow),Unacceptable,spack load,Chaining,"AMD, Intel, ARM","NVIDIA, AMD, Intel","gcc, LLVM, Fujitsu Compilers, armclang",Not Important,Slightly Important,Slightly Important,Not Important,Slightly Important,Slightly Important,Somewhat important,Slightly Important,Slightly Important,Slightly Important,Very Important,Slightly Important,N/A,Maybe,No,"Slack, Coworkers",Weekly,Probably not,Bad,OK,OK,Good,Support Spack in Fugaku,,When `spack install xxx` fails (frequently),,,
11/17/2020 18:53:15,Software Developer,Other Public Research Lab,Switzerland,No,Traditional HPC / Simulation,Used at my site,0,"Packages, Core Features, Documentation, Slack Discussions, Issues","0.15, develop",Ubuntu,"500-1,000","3.7, 3.8",Do it!,Do it!,spack load,"Environments, Binary Caches, build-env (debug a build), Externals in packages.yaml, Concretization preferences in packages.yaml, spack ci (generate GitLab Pipelines), Distributed Builds (srun spack install)","AMD, Intel","NVIDIA, AMD","gcc, LLVM, AMD hipclang",Critical,Not Important,Critical,Slightly Important,Not Important,Critical,Not Important,Not Important,Somewhat important,Slightly Important,Critical,Not Important,Proper compiler packages!,Maybe,No,"Documentation, Slack, Coworkers",Monthly,No,Good,Excellent,Good,Good,Spack is part of our CI pipelines to test our package against the latest dependencies. We use dev-build + binary mirrors to make this work. Further we containerize the full application to run MPI tests on our clusters.,sharing specs with coworkers,,Compilers as packages; there's so many instances of build dependencies that aren't handled well at the moment (in particular the AMD stack currently).,,
11/17/2020 18:56:41,Scientist/Researcher,Other Public Research Lab,Germany,No,"Traditional HPC / Simulation, AI/ML",Used at my site,3,Packages,custom fork,Debian,100 - 200,2.6,Unacceptable  (it's the only python on important machines),Unacceptable,Containers,"Module generation, Stacks (matrices in environments)","AMD, Intel","NVIDIA, AMD, Intel","gcc, LLVM",Very Important,Very Important,Very Important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Very Important,Not Important,,"Yes, I'd attend",No,"Documentation, Coworkers",Monthly,Probably not,Good,Good,Good,Good,,,,,,Keep it up!
11/17/2020 18:58:21,System Administrator,University HPC/Computing Center,United States,No,Traditional HPC / Simulation,Birds-of-a-feather (BOF) at conference,2,No,"0.12, 0.15",CentOS,10 - 100,"2.7, 3.5",I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),Lmod,"Environments, Module generation, spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml",Intel,NVIDIA,"gcc, Intel Compilers, PGI",Somewhat important,Critical,Somewhat important,Somewhat important,Very Important,Very Important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,More coordination with OpenHPC and other scientific software repos,"Yes, I'd attend",Yes,"Documentation, Slack",Daily,Probably,Excellent,Excellent,Excellent,Excellent,I use Spack to build software that is not available in OpenHPC repos.,Its ability to build any of 3000+ packages quickly.,Integration of Spack and OpenHPC. Maybe someone can provide a Spack recipe for building scientific software stack similar to OpenHPC's,SLURM 20 support,,Thanks for all that you do. Spack is one of my favorite tools as a sysadmin and Todd is one of my favorite people in the HPC community.
11/17/2020 18:59:20,Scientist/Researcher,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,"Traditional HPC / Simulation, High Energy Physics",Word of mouth,3,"Packages, Core Features, Slack Discussions, Issues","0.15, develop","macOS, Red Hat, CentOS",10 - 100,"3.6, 3.7, 3.8",Do it!,Do it!,"Spack environments, Lmod","Environments, Module generation, spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel","NVIDIA, AMD","gcc, Intel Compilers, LLVM, nvcc",Very Important,Slightly Important,Somewhat important,Not Important,Slightly Important,Slightly Important,Slightly Important,Slightly Important,Somewhat important,Not Important,Slightly Important,Somewhat important,,Maybe,Yes,"Documentation, Slack",Weekly,Probably,Excellent,OK,Good,Good,"Development environment, CI toolchain, institutional cluster deployment",,Concretization,,,
11/17/2020 19:02:01,User Support Staff,Other Public Research Lab,Sweden,No,Traditional HPC / Simulation,Word of mouth,3,"Slack Discussions, Issues","0.15, develop","Red Hat, CentOS, Fedora",100 - 200,"2.7, 3.6",Do it!,Do it!,"spack load, Lmod","Module generation, build-env (debug a build), spack external find, Concretization preferences in packages.yaml, Distributed Builds (srun spack install)","AMD, Intel, ARM","NVIDIA, AMD","gcc, Intel Compilers, NVIDIA Compilers (new PGI), AMD aocc, nvcc, armclang",Very Important,Somewhat important,Slightly Important,Not Important,Slightly Important,Slightly Important,Somewhat important,Slightly Important,Very Important,Somewhat important,Somewhat important,Not Important,None I can think of right now.,Maybe,No,"Documentation, Slack, spack help",Monthly,Probably not,OK,Good,Good,Good,Currently mostly for testing and/or benchmarking. In the future hopefully in production on our generally available large clusters.,Discoverability (spack list and info) and dynamic properties (variants and control over the dependency graph),It's a bit too dynamic at times (meaning you always get a new concretization and find new bugs..),,One example I went looking for not too long ago was amanzi-ats. The project seem to have some efforts done in the spack direction but nothing mainline yet.,
11/17/2020 19:04:50,Scientist/Researcher,Other Public Research Lab,Germany,No,"Traditional HPC / Simulation, Statistics / Data Analysis, AI/ML, Computer Science Research",Presentation,4,"Packages, Core Features, Slack Discussions, Mailing List, Issues","develop, custom fork","CentOS, Debian","> 1,000","2.7, 3.8",Do it!,I'd live (I can provide Python 3 somehow),"spack view, Containers","Environments, Module generation, Chaining, Stacks (matrices in environments), Binary Caches, build-env (debug a build), Python extensions (link python packages into interpreter prefix), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, ARM",NVIDIA,"gcc, LLVM",Critical,Very Important,Critical,Somewhat important,Somewhat important,Somewhat important,Slightly Important,Somewhat important,Very Important,Somewhat important,Very Important,Not Important,,"Yes, I'd present something!",Yes,"Documentation, Mailing List, Coworkers",Weekly,Probably not,Excellent,Good,Good,Good,"Tracking and providing external software dependencies for our software developments (neuromorphic hardware, software stack reaches from ""driver""-level (libusb or sockets) to user APIs (e.g. pytorch accelerator extension)), i.e. it provides the software for our hardware users, software developers and CI.",structured dependency tracking of our own software,concretization speed (but not 100% sure about performance as we miss O(3mon) of upstream development),failure reporting and overall speed,,
11/17/2020 19:07:25,Scientist/Researcher,University HPC/Computing Center,Germany,No,"Traditional HPC / Simulation, Statistics / Data Analysis, AI/ML",Used at my site,4,"Packages, Core Features, Issues","0.13, custom fork","Debian, Arch","> 1,000","2.7, 3.8",Do it!,I'd live (I can provide Python 3 somehow),"spack load, Spack environments, Environment Modules (TCL modules), spack view","Environments, Module generation, Chaining, Binary Caches, spack-python (Python scripting), Command Extensions, Python extensions (link python packages into interpreter prefix), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, NVIDIA Compilers (new PGI), LLVM, nvcc",Critical,Very Important,Critical,Not Important,Slightly Important,Very Important,Very Important,Somewhat important,Somewhat important,Slightly Important,Somewhat important,Not Important,better performance for binary caching,"Yes, I'd attend",Yes,"Documentation, Mailing List, GitHub",Monthly,No,Good,Good,OK,OK,"We use spack within singularity containers to have track all our system dependencies. If something breaks upon update, users can just move back to the previous container until the problem is fixed.","concretization, building views/environments","In general: Runtime performance.

Concretization for several hundred packages takes a very long time. We typically perform the concretization once and in parallel (in disjoint spack instances) for all disjoint toplevel packages. Afterwards, we use specfiles in all steps if supported (some change still await merge https://github.com/spack/spack/pull/13106).
While doing things in parallel, there sometimes are subtle notions as to when spack locks things, see https://github.com/spack/spack/issues/14055.

Also, the concretizer has problems identifying the newest version of package that is still supported by another package. We learned this the hard way when introducing Python 3 and had to pin all packages that still used Python 2 manually. See: https://github.com/spack/spack/issues/12431

Plus, it requires a bit too much of boiler-plate to keep packages in sync: https://github.com/spack/spack/pull/14002

Finally, creating and using binary caches via spack's capabilities is rather slow, as spack currently needs to make the caches location-agnostic by replacing all RPATHs. This is not needed for our workflow as we build containers in which the spack install will always reside at the exact same place → simple compression is far faster.",Concretizer,proper support for rust-based packages,"spack is the worst package manager there is, except for all the rest… ;)"
11/17/2020 19:08:29,Software Developer,University HPC/Computing Center,Switzerland,No,"Traditional HPC / Simulation, AI/ML",Word of mouth,0,"No, Core Features",0.15,"macOS, Red Hat, CentOS, Ubuntu, Debian, Arch, SuSE, Fedora, Alpine, Windows Subsystem for Linux (WSL)",10 - 100,3.8,Do it!,I'd live (I can provide Python 3 somehow),spack load,"Environments, Module generation, spack containerize, Externals in packages.yaml, spack ci (generate GitLab Pipelines), Distributed Builds (srun spack install)","AMD, Intel, ARM","NVIDIA, AMD, Intel","gcc, Intel OneAPI / dpc++, LLVM, AMD hipclang, nvcc, armclang",Slightly Important,Very Important,Very Important,Slightly Important,Very Important,Very Important,Somewhat important,Somewhat important,Very Important,Somewhat important,Very Important,Somewhat important,azure integration,"Yes, I'd attend",Yes,"Documentation, Slack, Coworkers",Weekly,No,OK,OK,OK,Good,,,,,,
11/17/2020 19:09:27,Scientist/Researcher,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,"Traditional HPC / Simulation, Statistics / Data Analysis, Computer Science Research",Word of mouth,2,"Packages, Documentation","0.15, develop","Red Hat, Debian",100 - 200,"3.6, 3.7, 3.8",Do it!,Do it!,"spack load, Spack environments, Lmod",Environments,"AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, LLVM, XL",Slightly Important,Critical,Somewhat important,Somewhat important,Very Important,Critical,Critical,Somewhat important,Somewhat important,Not Important,Somewhat important,Somewhat important,,Maybe,No,Documentation,Monthly,Probably not,Excellent,Excellent,Excellent,Excellent,,Supporting modern version in old systems (RHEL7),,Keep doing what you're doing,,
11/17/2020 19:10:43,Manager,University HPC/Computing Center,Saudi Arabia,No,"Traditional HPC / Simulation, Computer Science Research, Bioinformatics, High Energy Physics",Used at my site,3,"Packages, Issues",0.15,Ubuntu,200 - 500,"3.6, 3.7",Do it!,Do it!,Environment Modules (TCL modules),"Module generation, build-env (debug a build), Externals in packages.yaml",Intel,NVIDIA,"gcc, Intel Compilers, PGI",Slightly Important,Very Important,Slightly Important,Somewhat important,Somewhat important,Very Important,Very Important,Slightly Important,Somewhat important,Not Important,Slightly Important,Not Important,,"Yes, I'd attend",No,"Documentation, Coworkers",Monthly,Probably not,Good,OK,Excellent,Excellent,"We manage a scientific application stack for our researchers at KAUST. We have the usual suspects used in the HPC community, e.g. VASP, NetCDF, Gaussian, etc. We install new packages without sweating it because we have Spack. Sometimes (rarely nowadays) Spack doesn't have the package so we write our own that's in our KAUST (defined in etc/spack/repos.yaml) repo so we manage it through Spack. As a matter of fact we have contributed a few packages upstream to Spack.","It makes it very easy to install SW. Very easy. I recall when we had to fight with flags, compilers, dependencies. Spack made all that disappear. We just run spack install <package> [sometimes some flags] and you're done. We moved our scientific application stack from U16 to U18 in a week thanks to spack.","My biggest pain point was resolved in 0.14 (if I recall correctly): Spack reusing existing packages. The previous Spack (version 0.12) version would install OpenMPI multiple times, e.g. spack find openmpi give me 2 versions (one for GCC, the other for INTEL) on Spack 0.15; on Spack 0.12 I get 10 different OpenMPI installations!","We at KAUST sometimes have to extend Spack packages. It would be nice to find a way to do it through inheritance instead of copying the package to add our bits. BTW, it might already be possible but I never tried :P I'd also like to have some way to reinstall all my packages with one command, e.g. install our current U18 packages for U20 with spack install --all U20 or  spack find packages_from_U18 | spack install -","VASP (In think it's in develop but not in v0.15), some commercial packages (for which we wrote custom packages so we haven't pushed them upstream) like COMSOL, ANSYS, ENVI.","Keep up the great work! You guys rock, Spack has been awesome for us. I keep selling it to my colleagues, my network, whoever has to maintain a scientific application stack. I really appreciate your hard work and that you have created a wonderful community."
11/17/2020 19:13:28,User Support Staff,University HPC/Computing Center,Italy,No,Visualization,Technical Paper,3,"Packages, Mailing List, Issues",0.14,"Red Hat, CentOS, Ubuntu",10 - 100,2.7,I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),Environment Modules (TCL modules),"Environments, Module generation, Chaining, Externals in packages.yaml, Concretization preferences in packages.yaml","Intel, IBM Power",NVIDIA,"gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, nvcc, XL",Somewhat important,Very Important,Very Important,Slightly Important,Somewhat important,Somewhat important,Slightly Important,Very Important,Somewhat important,Very Important,Somewhat important,Very Important,#11598 #11951,"Yes, I'd attend",No,"Documentation, Mailing List, Coworkers",Monthly,Probably not,Excellent,Excellent,OK,Excellent,"I've used myself spack to deploy VNC/X11/Opengl stack user side on our clusters, Now start to experiment spack for more  widespread modules stuff like base numerical libraries, OpenMpi, Cuda build environments, on Power9 clusters....
We run an experimental build upon Power9 arrival, based on 0.14... Unfortunately Power9 + Cuda  to Spack.... ON that environment, was not a ""just work"" experience, likely it was not stable enough to convince user support team to switch from custom scripts. Nevertheless, still pushing as I strongly believe Spack benefit over custom scripts by far outweighs the hassle of switching",Installing deep dependencies for viz gui packages like Paraview on clusters,"Not properly working big packages like QT, Paraview, Visit,  No easy way to select a combination of PR and config setup to work around bugs,.
Did not found a way to accelerate recipes patching for packages that require long build time ( like Qt and Paraview). Not many testing / benchmark packages usable for early finding of problems in base packages such as Python, Mpi, X11, Qt",Improve build testing,,"PR testing would really be welcomed to speed up PR merging, expecially for packages"
11/17/2020 19:14:49,Scientist/Researcher,Other Public Research Lab,United States,Yes,"Traditional HPC / Simulation, Computer Science Research",Used at my site,4,"Slack Discussions, Issues",develop,"macOS, Red Hat, CentOS, Debian",100 - 200,"3.6, 3.7, 3.8",Do it!,Do it!,spack load,"Environments, Module generation, spack containerize, Chaining, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, LLVM, AMD hipclang",Very Important,Critical,Very Important,Not Important,Not Important,Critical,Slightly Important,Very Important,Very Important,Not Important,Very Important,Not Important,"Better control of developer workflows, some kind of versioning of concretization logic that is separate from regular spack code updates... currently changes in spack code (especially package.py) seems to change concretization with repeated runs.","Yes, I'd attend",No,"Documentation, Slack",Monthly,No,OK,Excellent,OK,Excellent,Installing and running ECP ExaWind stack on DOE systems,Consistent builds of the dependency set for building Trilinos.,Developer mode ,Versioning of containerization or some way to easily debug why `spack spec <package>` returns different concretizations with different spack commits. ,"Not really a package, but better support for handling CUDA/HIP/DPC++ etc for Trilinos. ","Spack is a great software for wrangling software, thanks for your efforts."
11/17/2020 19:16:40,Scientist/Researcher,University HPC/Computing Center,United States,No,AI/ML,Word of mouth,5,"Packages, Core Features, Documentation, Slack Discussions, Mailing List, Issues",develop,"macOS, Red Hat, Windows Subsystem for Linux (WSL)","> 1,000","2.6, 2.7, 3.8",Do it!,Do it!,"spack load, Spack environments","Environments, build-env (debug a build), spack-python (Python scripting), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, LLVM, CCE (Cray Compilers)",Critical,Critical,Critical,Very Important,Very Important,Not Important,Somewhat important,Very Important,Slightly Important,Not Important,Slightly Important,Slightly Important,Better mixed compiler support (clang + gfortran),"Yes, I'd present something!",Yes,"Documentation, Slack, GitHub",Weekly,No,Good,Excellent,Excellent,Excellent,"Environments on macOS, Cray cluster, and Linux cloud",,Reinstallation every time hashes change ,"New concretizer, maintainer bot",If there were I would have added them,
11/17/2020 19:17:34,Software Developer,Other Public Research Lab,Italy,No,Traditional HPC / Simulation,Word of mouth,1,No,"0.14, 0.15","Red Hat, CentOS, Ubuntu",10 - 100,3.5,Do it!,I'd live (I can provide Python 3 somehow),"spack load, Spack environments","Module generation, build-env (debug a build), spack-python (Python scripting), Externals in packages.yaml, Concretization preferences in packages.yaml","Intel, IBM Power",NVIDIA,"gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, nvcc",Slightly Important,Very Important,Somewhat important,Slightly Important,Somewhat important,Slightly Important,Very Important,Somewhat important,Very Important,Not Important,Very Important,Not Important,notification about new packages available,"Yes, I'd attend",Yes,"Documentation, Mailing List, Coworkers",Weekly,Probably not,Excellent,Good,Good,Good,,,,,,
11/17/2020 19:18:51,Software Developer,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,No,High Energy Physics,Presentation,4,"Packages, Core Features, Slack Discussions",develop,"macOS, CentOS",10 - 100,"2.7, 3.6",Do it!,Do it!,"spack load, Environment Modules (TCL modules)","Module generation, Chaining, Binary Caches, Command Extensions","AMD, Intel",NVIDIA,gcc,Very Important,Very Important,Very Important,Not Important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Critical,Not Important,Critical,Not Important,,Maybe,No,"Documentation, Slack, Mailing List, Coworkers",Yearly,Probably not,OK,Excellent,Good,Excellent,Building full software stack,"Environment module, binary packages",Concretization takes minutes for our software stack,,,
11/17/2020 19:19:39,Software Developer,University HPC/Computing Center,Switzerland,No,Traditional HPC / Simulation,Word of mouth,1,Packages,develop,"CentOS, Ubuntu",10 - 100,3.8,Do it!,Do it!,spack load,"Environments, Module generation, Chaining, build-env (debug a build)","AMD, Intel","NVIDIA, AMD","gcc, Intel Compilers, NVIDIA Compilers (new PGI), LLVM, AMD hipclang, nvcc, CCE (Cray Compilers)",Somewhat important,Slightly Important,Not Important,Not Important,Very Important,Very Important,Very Important,Very Important,Critical,Not Important,Critical,Not Important,,Maybe,No,"Documentation, GitHub",Monthly,Probably not,Good,OK,Good,Good,,,,Handling of compilers. I still find it confusing that one first has to build-install-find a compiler to be able to use it in an environment.,,
11/17/2020 19:20:39,Scientist/Researcher,University HPC/Computing Center,Japan,No,Computer Science Research,Presentation,1,No,0.15,"CentOS, Ubuntu",1 - 10,3.8,Do it!,Do it!,spack load,"Environments, spack containerize","AMD, Intel","NVIDIA, AMD",gcc,Somewhat important,Critical,Somewhat important,Somewhat important,Very Important,Somewhat important,Somewhat important,Very Important,Somewhat important,Slightly Important,Somewhat important,Not Important,,Maybe,Yes,"Documentation, Slack, Coworkers",Weekly,Probably not,Excellent,Excellent,Excellent,Excellent,I use Spack to use the latest libraries that are not provided by the old CentOS release of the supercomputer.,I can create a reliable managed environment by using package config files. It really help to reproduce the develop environment.,It seems that we should specify external package path every time so it would be great if Spack can detect preinstalled libraries.,,,You did a great job to create a good community for Spack!
11/17/2020 19:22:06,Scientist/Researcher,University HPC/Computing Center,Canada,No,High Energy Physics,Word of mouth,1,"Packages, Documentation, Slack Discussions","0.15, develop","Red Hat, CentOS, Ubuntu",100 - 200,"3.6, 3.7, 3.8",Do it!,Do it!,"spack load, Spack environments, Lmod, Environment Modules (TCL modules)","Environments, spack containerize, Binary Caches, build-env (debug a build), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml, Distributed Builds (srun spack install)","AMD, Intel",NVIDIA,"gcc, LLVM",Somewhat important,Somewhat important,Not Important,Not Important,Slightly Important,Somewhat important,Slightly Important,Not Important,Somewhat important,Not Important,Not Important,Not Important,Ability to have the same package in multiple repositories so we can override some packages in 0.15 with more recent versions. ,"Yes, I'd attend",Yes,"Documentation, Slack",Weekly,No,Excellent,Excellent,Good,Good,"We use spack to provide 3 consistent entry points into our nuclear physics software environment: cvmfs, build_caches, containers. ",Ease of package development while maintaining flexibility ,Better support for populating build_caches with packages for multiple operating systems. ,Focus on getting users to use environments instead of spack load individual packages. Most of my time goes to addressing misconceptions that result from spack load. ,"cernlib: it's old, unmaintained, struggles with 64 bit, but still used in key Monte Carlo event generators (I have a version I'll push as a pr)",
11/17/2020 19:24:02,All of the Above,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,No,High Energy Physics,Word of mouth,4,"Core Features, Mailing List, Issues",develop,"Ubuntu, Debian",1 - 10,2.7,Do it!,Do it!,"spack load, spack view",Module generation,Intel,NVIDIA,"gcc, LLVM, nvcc",Not Important,Somewhat important,Not Important,Not Important,Slightly Important,Somewhat important,Slightly Important,Somewhat important,Very Important,Not Important,Slightly Important,Not Important,,Maybe,No,"Documentation, Mailing List, GitHub",Daily,No,Good,Good,Good,Good,"Currently, I am using Spack to build software for a DAQ and Spack provides a great alternative to some of the horribly wrong patterns that have been traditionally pushed in our space.  We are in the process of constructing the initial package.py's for our upper layers and then will work on hopefully getting Spack accepted as ""official"" by the rest of the group. ","Technically, the automation.  But, I think also that a spack repo becomes a point of concentration of human expertise that can be then shared.  Also, important is the proper separation of concerns, ie not having Spack idioms be invasive in the native package build mechanism.  An obvious thing that other build systems get horribly wrong.

The documentation is also very good.  As I mentioned, I've been away from Spack for a while and having to relearn many little details and am able to do that fairly quickly with the docs and also the CLI --help.  ",The build debugging mentioned above.  ,"Maybe a small thing but I am finding some lack of ""hermeticness"" of some spack commands run while inside a Spack Environment.  Ie, the command acts on the broader Spack install instead of staying with the Environment.  It's possible I am missing intent and in any case it's small stuff that should result in a bug ticket once I understand better and not any sea change.","Generally, no.  The only ones missing are top-of-the-stack domain specific ones.  But, arguably these are better placed in their own repo.",I've been away from spack for a bit and am getting back into it now.  My largest troubles come in debugging failures in a build.  I actually didn't clue into build-env which may be a big help.
11/17/2020 19:25:50,Scientist/Researcher,University HPC/Computing Center,United States,No,"Traditional HPC / Simulation, AI/ML, Computer Science Research",Word of mouth,3,"Packages, Documentation, Slack Discussions, Issues",develop,"Red Hat, Ubuntu, Fedora",200 - 500,"3.6, 3.7, 3.8",Do it!,Do it!,Lmod,"Environments, Module generation, spack containerize, Externals in packages.yaml, Concretization preferences in packages.yaml",Intel,"NVIDIA, Intel","gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, nvcc",Very Important,Somewhat important,Somewhat important,Somewhat important,Very Important,Very Important,Somewhat important,Slightly Important,Not Important,Not Important,Very Important,Not Important,Whatever makes compiler proper DAG representation.,Maybe,Yes,"Documentation, Slack",Monthly,No,OK,Excellent,OK,Excellent,"Personal and professional system setup, usually small lab groups or desktop machines but also a couple of servers.","It usually works perfectly for many things, so any battle to get it working is TOTALLY worth the effort because now I get optimized builds <3","Concretization failure messages are usually not very helpful and you have to go hunting / guessing.  Those have been getting a LOT better over time though, and I definitely understand that it's not as easy as including a backtrace aka while painful, it's pain is well known on many levels ;)",Python3.  The backwards compat is seriously holding back the code quality.  Spack is going to incur significant technical debt if this continues.,"https://github.com/icecc/icecream is on my list to package but it's a bit complicated.  I don't think many people have a desire for it either, so low priority.","Can we get additional CUDA maintainers please?  I don't think I can do this anymore, ax3l isn't getting any useful support from me."
11/17/2020 19:26:35,Software Developer,University HPC/Computing Center,Switzerland,No,Traditional HPC / Simulation,Used at my site,5,"Packages, Issues","0.15, develop",Red Hat,"> 1,000","2.7, 3.6",Do it!,Do it!,"Spack environments, Lmod","Environments, Module generation, Chaining, Stacks (matrices in environments), build-env (debug a build), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, NVIDIA Compilers (new PGI), LLVM, nvcc",Very Important,Very Important,Somewhat important,Slightly Important,Somewhat important,Somewhat important,Very Important,Very Important,Somewhat important,Somewhat important,Very Important,Not Important,Treat compilers as build dependencies,"Yes, I'd attend",No,"Documentation, Coworkers",Monthly,Probably not,Good,Good,Good,Excellent,"- Deploy a software stack (with internal ci)
- Get request from users
- Check if it is in spack
- Add the package if needed (with internal code review)
- Add the software to the  stack list (code review and internal ci)
- If relevant push package upstream",Being able to relatively easily deploy a coherent software stack for our users,When the concretizer is not working properly,Continue the good work,,
11/17/2020 19:27:44,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,No,"Computer Science Research, Compiler Testing",Word of mouth,0,Packages,"0.15, develop","macOS, Red Hat, Arch",100 - 200,"3.7, 3.8",Do it!,Do it!,"Spack environments, Lmod","Environments, Module generation, Stacks (matrices in environments), build-env (debug a build), spack-python (Python scripting), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, NVIDIA Compilers (new PGI), armclang",Somewhat important,Very Important,Very Important,Not Important,Somewhat important,Very Important,Somewhat important,Critical,Somewhat important,Somewhat important,Very Important,Not Important,,"Yes, I'd present something!",Yes,"Documentation, Slack, Coworkers",Weekly,Probably,OK,Excellent,OK,OK,I build stacks for multiple operating systems using environments using spack-python scripting for ease of use. ,,Python - virtual dependency; Fail-fast; repos.yaml does not accept env vars; built-in retry; better treatment of stacks (unreliable behavior in stack builds),Python as a virtual dependency,,
11/17/2020 19:28:28,Manager,University HPC/Computing Center,United States,No,Traditional HPC / Simulation,Twitter,0,Mailing List,0.15,"macOS, CentOS",10 - 100,3.6,Do it!,Do it!,Lmod,"Environments, Module generation, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel","NVIDIA, AMD","gcc, Intel Compilers, NVIDIA Compilers (new PGI), AMD aocc, AMD hipclang",Somewhat important,Very Important,Somewhat important,Not Important,Slightly Important,Very Important,Critical,Somewhat important,Very Important,Slightly Important,Critical,Not Important,Better community sharing of spack recipes,"Yes, I'd attend",No,"Documentation, Mailing List, Coworkers",Weekly,Probably not,Good,Good,OK,OK,Our primary use case is building applications for users of our cluster.,Isolating environments so that different application dependencies do not conflict,"Everything seems ""special"" - hard to settle on a standard configuration. ",Introduce more guided response to concretization errors and dependencies,AMD compilers with awareness of NUMA/processor affinity considerations.,"It's easy to create a real tangle of versions and special builds. I think the project should work to maintain good communication with the application developers, so that standard or common/expected versions and dependency sets can be more clearly identified"
11/17/2020 19:29:44,Manager,University HPC/Computing Center,United States,No,"Traditional HPC / Simulation, Statistics / Data Analysis, Bioinformatics",Birds-of-a-feather (BOF) at conference,4,Slack Discussions,0.15,"macOS, CentOS, SuSE",10 - 100,3.5,Do it!,Do it!,Environment Modules (TCL modules),"Environments, Module generation, spack containerize, Chaining, Binary Caches, build-env (debug a build), Concretization preferences in packages.yaml","AMD, Intel, ARM","NVIDIA, Intel","gcc, Intel Compilers, PGI, nvcc",Somewhat important,Very Important,Somewhat important,Slightly Important,Somewhat important,Slightly Important,Very Important,Slightly Important,Very Important,Slightly Important,Critical,Not Important,Update packages to new versions ,"Yes, I'd attend",No,Documentation,Monthly,Probably not,Excellent,Excellent,Good,Excellent,,Installing packages particularly ones in bioinformatics that have a large set of dependencies,,"Nothing, you guys are going a great job.",,"You guys are great. However, I would prefer to split the tutorials to introductory/intermediate and advanced. I've attended your workshop at SC19 and the one using Amazon a couple of months ago. I've tuned off the later half of the workshops after keeping pace with newer developments from the first half. Splitting these with a time gap would help an experience user like me to learn and incorporate the more advanced stuff like stacks, matrices and development tools."
11/17/2020 19:30:47,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,No,Traditional HPC / Simulation,Word of mouth,3,"Packages, Documentation, Slack Discussions, Mailing List, Issues",develop,"Red Hat, CentOS, Ubuntu, Windows Subsystem for Linux (WSL)","500-1,000","3.6, 3.8",Do it!,Do it!,"Lmod, Environment Modules (TCL modules)","Module generation, spack containerize, Python extensions (link python packages into interpreter prefix), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD","gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, AMD hipclang, nvcc, XL, CCE (Cray Compilers), armclang",Slightly Important,Somewhat important,Slightly Important,Not Important,Not Important,Slightly Important,Slightly Important,Somewhat important,Slightly Important,Not Important,Not Important,Somewhat important,I would see package updates and non feature patches for older versions of spack.,Maybe,Yes,"Documentation, Slack, Mailing List, Coworkers",Weekly,Probably,Excellent,Good,OK,Good,"I need to use significantly different workflows for different systems.  In some cases (WSL), I build everything at $HOME and provide lmod modules. Other cases, I install to NFS space and install either lmod or env modules (based on the system default).  I also support several air gap systems.",My release process is much simpler now that I can rely on spack.,"(1) It is still really hard to build products that provide a GUI (gtk+, X11, etc). The build recipes are frequently broken; (2) A tutorial that captures best practices for 'building on an airgap system'; (3) Cray systems continue to be a PIA.",(1) Improved robustness of package recipes.  (2) Examples of how to use a cmake build system to automatically create a local spack instance and install dependencies needed by our developers (e.g. on a Mac Book),meld,"Love the product.  I wish it worked on Windows, but that's a whole different game (and vcpkg is filling that gap)."
11/17/2020 19:31:49,Scientist/Researcher,University HPC/Computing Center,United States,No,AI/ML,Word of mouth,5,"Packages, Core Features, Documentation, Slack Discussions, Mailing List, Issues",develop,"macOS, Red Hat, Windows Subsystem for Linux (WSL)","> 1,000","2.7, 3.8",Do it!,Do it!,"spack load, Spack environments","Environments, build-env (debug a build), spack-python (Python scripting), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, LLVM, CCE (Cray Compilers)",Critical,Critical,Critical,Very Important,Very Important,Not Important,Somewhat important,Very Important,Slightly Important,Not Important,Slightly Important,Slightly Important,Better mixed compiler support (clang + gfortran),"Yes, I'd present something!",Yes,"Documentation, Slack",Weekly,No,Good,Excellent,Excellent,Excellent,"Environments on macOS, Cray cluster, and Linux cloud",,Reinstallation every time hashes change ,"New concretizer, maintainer bot",If there were I would have added them,
11/17/2020 19:33:08,System Administrator,University HPC/Computing Center,United States,No,"Traditional HPC / Simulation, Statistics / Data Analysis, AI/ML, Bioinformatics",Birds-of-a-feather (BOF) at conference,3,"Packages, Documentation, Slack Discussions, Mailing List, Issues",develop,"Red Hat, Ubuntu, Debian",10 - 100,"3.6, 3.8",Do it!,Do it!,spack load,"Environments, Module generation, Externals in packages.yaml, Concretization preferences in packages.yaml",Intel,NVIDIA,"gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, nvcc",Slightly Important,Slightly Important,Not Important,Not Important,Somewhat important,Somewhat important,Slightly Important,Not Important,Not Important,Not Important,Not Important,Not Important,Sysadmin manual documentation,"Yes, I'd present something!",Yes,"Documentation, Slack, Mailing List",Monthly,Probably not,Good,Good,Good,Good,"Clone separate spack repos to expose modules on our cluster.  Wasting disk space is fine, because with several of us sysadmins it's more important to now inadvertently change or break a package installation, e.g. by updating the spack git repo.  We almost always need to create environments and set concretization preferences.","Having more reproducibility, flexibility and control than Singularity containers.  Being able to contribute changes back instead of Sysiphean patching packages for my cluster only.","Lots of technical knowledge involved in a typical package install that puts it out of reach from a non-technical end user.  Some of this can be solved with documentation, but other parts with better error messages, but I suspect mostly we're waiting for some dependency graphs to mature.",Needs to be more beginner friendly: maybe fill in knowledge and training gaps for non-CS researchers with basic ideas about compiling software and suggestions on how to go about doing things,,This project makes me enjoy coming into work.
11/17/2020 19:34:17,Scientist/Researcher,Cloud Provider,United States,No,"Traditional HPC / Simulation, AI/ML",Word of mouth,1,"Packages, Slack Discussions, Mailing List","0.13, 0.15, develop","CentOS, Ubuntu, Amazon Linux","> 1,000","2.7, 3.5, 3.6, 3.7, 3.8",I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),Environment Modules (TCL modules),"Module generation, Chaining, Stacks (matrices in environments), Binary Caches, spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml, Distributed Builds (srun spack install)","AMD, Intel, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc, armclang",Somewhat important,Very Important,Very Important,Critical,Critical,Somewhat important,Somewhat important,Slightly Important,Not Important,Not Important,Somewhat important,Slightly Important,Easier setup for vanilla environments (recall spack bootstrap),"Yes, I'd present something!",Yes,"Documentation, Slack, Coworkers",Weekly,"Yes, definitely!",Good,Excellent,Good,Excellent,,"Well-defined package specifications and solid concretization. Very useful product, and it gives us peace of mind that compiled binaries are truly HPC-ready.  ",Installing and configuring Spack for multi-user environments. ,Don't lose momentum. ,ARM and FPGA libraries. OneAPI. ,"Provide a single pane example (e.g., separate git repo) of a full institution deployment so users can see example modules.yaml, packages.yaml, etc. that would be produced by the end of the Spack tutorial. Other than iterating all the way through the tutorial, it is hard for new users to identify when they have configured spack at ""production"" quality. "
11/17/2020 19:36:39,User Support Staff,University HPC/Computing Center,United States,No,"Traditional HPC / Simulation, Computer Science Research, Compiler Testing",Birds-of-a-feather (BOF) at conference,1,"Slack Discussions, Issues","0.13, develop",CentOS,100 - 200,"2.7, 3.7",Unacceptable  (it's the only python on important machines),I'd live (I can provide Python 3 somehow),Lmod,"Environments, Module generation, Chaining, build-env (debug a build), Command Extensions, Python extensions (link python packages into interpreter prefix), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel","NVIDIA, AMD","gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc",Critical,Very Important,Somewhat important,Somewhat important,Slightly Important,Very Important,Critical,Somewhat important,Somewhat important,Very Important,Very Important,Not Important,Isolation of spack-core and package recipes. Ability to update packages without redeploying a new version of Spack.,"Yes, I'd present something!",Yes,"Documentation, Slack, GitHub",Weekly,Probably,Good,Excellent,OK,Excellent,Deploying packages across multiple clusters. Isolated Spack instance per cluster.,User community,"1) Upgrading packages. 2) Handling compiler-agnostic packages (e.g. intel, mkl, cuda, cudnn, aocl, matlab etc.) 3) Module file customization (naming, hierarchy, etc.)","1) Much better API documentation (methods and properties of objects, introspection). 2) Freezing Spack core APIs and eliminate modifications that break multiple packages across minor versions (e.g., package renaming, renaming object properties etc.). 3) IDE support for package developers, if possible.",Many licensed software.,Thank you for the great work so far and the fantastic support! Would love to contribute to Spack in future as our staff become more experienced with Spack.
11/17/2020 19:37:22,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,Traditional HPC / Simulation,Word of mouth,3,Packages,0.15,"macOS, Red Hat",10 - 100,3.7,Do it!,Do it!,Environment Modules (TCL modules),"Module generation, spack external find, Externals in packages.yaml","AMD, Intel, IBM Power","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc, XL, CCE (Cray Compilers)",Slightly Important,Very Important,Slightly Important,Slightly Important,Slightly Important,Somewhat important,Critical,Very Important,Very Important,Somewhat important,Somewhat important,Not Important,"1. Variants for virtual dependencies e.g., blas+int64 to install blas with 64-bit int support
2. Uniform variants for common options e.g., +int64 for using math libraries with 64-bit integers ","Yes, I'd attend",Yes,"Documentation, GitHub",Monthly,Probably not,Good,Excellent,Good,Excellent,"I'm a math library developer and use spack to build third party libraries e.g., blas, lapack, MPI, hypre, SuperLU_MT, SuperLU_DIST, PETSc, and Trilinos both for developing on my laptop and for continuous integration on a dedicated workstation.

As new releases of those libraries are released I'll build and test with them in different variations of precision (single, double, extended) and index size (32- or 64-bit integers). Once or twice a year I'll install the latest gcc and llvm through spack and rebuild my software stack with it. To load the spack installed software into my environment I use TCL modules. ",Having a simple and easy way to build many different combinations of software packages. Before spack I relied on my own set of bash scripts and it's great to have a much more capable and flexible tool to do the job.,"1. Lack of common variants and variants for virtual dependencies
2. Long build times for some packages
3. Several packages do not support macOS + gcc e.g., CMake and python. However, when I point to an externally installed version in packages.yaml spack will throw an error when concretizing saying it can't build the package with gcc on macOS. I work around this by commenting out the error check in the package I'm building but it would be nice if Spack could note this package is provided externally and not throw the error.
4. Some packages not setting the rpath correctly on macOS e.g., parmetis and petsc not using the full path to metis. ",,,It would be great if https://github.com/spack/spack-configs included more DOE machines and were updated more frequently. If the administrators at computing centers provide these files somewhere it does not seem to be well advertised to users.
11/17/2020 19:38:40,System Administrator,University HPC/Computing Center,United States,No,"Traditional HPC / Simulation, Statistics / Data Analysis, Bioinformatics",Technical Paper,2,"Packages, Slack Discussions",develop,CentOS,200 - 500,3.8,Do it!,Do it!,Lmod,"Module generation, Chaining, build-env (debug a build), spack-python (Python scripting), Externals in packages.yaml, Concretization preferences in packages.yaml, Distributed Builds (srun spack install)",Intel,NVIDIA,"gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI)",Very Important,Somewhat important,Very Important,Not Important,Slightly Important,Somewhat important,Somewhat important,Very Important,Slightly Important,Not Important,Somewhat important,Not Important,,Maybe,No,"Documentation, Slack, Coworkers",Weekly,Probably not,OK,Excellent,OK,Good,spack install; read debug messages ; try again,installing multiple versions of the same package with different options for each,"Packages that install in bizarre ways #18975
compiler flags in packages that don't match my systems!",,,
11/17/2020 19:41:57,All of the Above,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,"Traditional HPC / Simulation, Computer Science Research",Word of mouth,5,"Packages, Core Features, Slack Discussions, Issues",develop,"macOS, CentOS","> 1,000",3.7,Do it!,Do it!,"spack load, Spack environments, Lmod, Environment Modules (TCL modules)","Environments, Module generation, Chaining, Stacks (matrices in environments), Externals in packages.yaml, Concretization preferences in packages.yaml, Distributed Builds (srun spack install)","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc",Slightly Important,Not Important,Not Important,Slightly Important,Slightly Important,Slightly Important,Slightly Important,Slightly Important,Somewhat important,Slightly Important,Slightly Important,Not Important,Ability to set preferences for dependent packages in packages.yaml,"Yes, I'd present something!",No,"Documentation, Slack",Monthly,Probably not,Good,Good,OK,Good,I use Spack to create environments to test applications in which I develop and I also maintain large sets of software for my own group on our machines.,"Once I have a specific configuration set up for a particular machine, I can be a lot more efficient with my work and developing applications than I ever have been without Spack. I work on almost all open DOE machines.","Whenever I try the latest Spack to deploy a large amount of software on a machine, there are tons of version conflicts, and build nuance problems between all of the packages that pop up. I don't have any ideas on what can be done about it and it's not really Spack's fault, but that's usually my biggest issue, and my favorite thing about Spack is when it solves all these issues automatically for me.","All the new GPU programming models will become a problem soon. However, I'm mostly satisfied with my Spack experiences. I realize Spack is trying to tackle a very large problem space so it's hard for me to complain about anything or think it can be done better.",A more complete VisIt to replace their own build script.,
11/17/2020 19:43:01,Software Developer,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,No,Traditional HPC / Simulation,Birds-of-a-feather (BOF) at conference,1,"Slack Discussions, Issues",develop,CentOS,10 - 100,"2.7, 3.8",I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),"spack load, Lmod","Module generation, build-env (debug a build), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml",Intel,NVIDIA,"gcc, Intel Compilers",Somewhat important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Very Important,Critical,Very Important,Very Important,Very Important,Critical,Not Important,Better documentation on CI processing..,"Yes, I'd attend",Yes,"Documentation, Slack, Coworkers",Monthly,Probably not,OK,Good,Good,Good,,switching version of apps,intel compilers,better external package support,,
11/17/2020 19:43:59,Scientist/Researcher,University HPC/Computing Center,Norway,No,High Energy Physics,Word of mouth,1,"Slack Discussions, Mailing List",0.15,Debian,10 - 100,3.8,Do it!,Do it!,Lmod,"Environments, Module generation, spack-python (Python scripting)","AMD, Intel","NVIDIA, AMD","gcc, Intel Compilers, PGI",Somewhat important,Very Important,Somewhat important,Not Important,Very Important,Very Important,Somewhat important,Slightly Important,Slightly Important,Not Important,Very Important,Not Important,,"Yes, I'd attend",Yes,"Documentation, Mailing List",Daily,Probably not,Good,Excellent,OK,Good,I am a professor of theoretical physics that use spack to maintain the local cluster  that I and the people in my group  use in our research,,,Better support from spack for the various options provided by configure scripts of the software package in question,,A great software
11/17/2020 19:44:55,Scientist/Researcher,Other Public Research Lab,Canada,No,"Traditional HPC / Simulation, Computer Science Research",Birds-of-a-feather (BOF) at conference,5,"Packages, Core Features, Mailing List",develop,"macOS, Ubuntu",10 - 100,3.7,Do it!,Do it!,"Spack environments, spack view","spack containerize, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM",NVIDIA,"gcc, LLVM",Slightly Important,Not Important,Not Important,Not Important,Critical,Very Important,Slightly Important,Slightly Important,Slightly Important,Not Important,Not Important,Not Important,Create binary packages that I can use without Spack (e.g. self-consistent sets of statically linked binaries / libraries),Maybe,Yes,"Documentation, Mailing List",Monthly,No,Bad,Good,Good,Bad,,,Build times are much too long. Using OS packages is tedious to set up (need to create yaml file).,,,
11/17/2020 19:46:21,Software Developer,Company,United States,No,"Traditional HPC / Simulation, Embedded Systems",Word of mouth,2,"Slack Discussions, Issues","0.15, develop",Ubuntu,100 - 200,"3.6, 3.7",Do it!,Do it!,Spack environments,"Environments, Binary Caches, build-env (debug a build), spack-python (Python scripting), Python extensions (link python packages into interpreter prefix), Concretization preferences in packages.yaml","Intel, ARM",NVIDIA,"gcc, LLVM, armclang",Very Important,Somewhat important,Somewhat important,Somewhat important,Not Important,Critical,Not Important,Slightly Important,Somewhat important,Not Important,Somewhat important,Not Important,"Spack develop (PR#15256), new concretizer, better git integration, better buildcache support,","Yes, I'd attend",Yes,"Documentation, Slack",Weekly,Probably,OK,Excellent,Good,Good,"Developing proprietary 1st party packages with consistent build results across multiple architectures, usually requiring very recent 3rd party packages.",Transitive dependency tracking for large applications with many components being developed independently.,"Builtin packages being packaged with Spack itself makes it difficult to upgrade Spack without having to repopulate buildcaches and adjust dependencies slightly when new conflicts or versions are released. Also, floating versions (like develop branches) break both the source mirror and build cache in subtle ways.",Improve workflows related to developing packages in Spack.,,Awesome community support! Keep up the great work!
11/17/2020 19:47:23,Scientist/Researcher,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,"Traditional HPC / Simulation, High Energy Physics",Word of mouth,4,"Packages, Core Features, Documentation, Slack Discussions, Issues",develop,"macOS, Red Hat, CentOS, Ubuntu, Debian, Alpine","> 1,000","3.7, 3.8",Do it!,Do it!,"spack load, Spack environments, Lmod","Environments, Module generation, Chaining, build-env (debug a build), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml, Distributed Builds (srun spack install)","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel OneAPI / dpc++, NVIDIA Compilers (new PGI), LLVM, AMD hipclang, nvcc, armclang",Critical,Very Important,Very Important,Somewhat important,Very Important,Critical,Very Important,Very Important,Very Important,Very Important,Very Important,Not Important,Public binary packages for develop (or more aggressive search for matching ones),"Yes, I'd present something!",Yes,"Documentation, Slack",Weekly,Probably not,Good,Excellent,Good,Excellent,"We are ECP app developers and need good C++ development environments on Linux, macOS, and the three major DOE sites. At the latter, Spack chains should be promoted and documented.","Clear and to-the-point package syntax, the great community, the spec syntax, (anonymous) environments.","(1) Kick-starting with Spack on HPC systems is not clear, we need docs what the recommended workflows on Summit, Cori et al. are (e.g. what packages to reuse, how to get started in few lines of code, what not to re-compile, where to store the compiled outputs to filesystem-wise, etc.).
(2) concretization errors in environments are not helpful, atm. this is problematic, because my environments are huge.
(3) macOS CI for each PR and binary packages.
(4) As a package maintainer, I would like to express in some points concretization preferences in my package (e.g. if I know conflicts with some MPI implementations, which will currently just default to a conflicting spec).",,Cling (I failed because the LLVM package is too complex for me to hook into),
11/17/2020 19:48:04,Software Developer,Other Public Research Lab,United States,No,Statistics / Data Analysis,Tutorial,1,"Packages, Slack Discussions",develop,"Red Hat, Ubuntu",1 - 10,"2.7, 3.8",I'd live.  (I can provide 2.7 somehow),Do it!,"spack load, Spack environments","Environments, spack containerize, Stacks (matrices in environments), build-env (debug a build), Externals in packages.yaml",Intel,NVIDIA,"gcc, LLVM, nvcc",Very Important,Very Important,Slightly Important,Slightly Important,Slightly Important,Somewhat important,Somewhat important,Slightly Important,Very Important,Not Important,Somewhat important,Not Important,improved concretization,Maybe,Yes,"Documentation, Slack",Weekly,No,Excellent,Excellent,Good,Excellent,software development and testing,easy installation of dependent packages in multiple variants for software development,"c++ language standard dependencies, build dependency blow-up",improved concretizer,,I'd like to see improvements in containerization support in Spack
11/17/2020 19:48:54,Scientist/Researcher,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,No,Traditional HPC / Simulation,Used at my site,1,No,0.15,Red Hat,1 - 10,3.5,I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),spack load,Module generation,"AMD, Intel","NVIDIA, Intel","Intel Compilers, Intel OneAPI / dpc++, NVIDIA Compilers (new PGI)",Somewhat important,Very Important,Somewhat important,Not Important,Somewhat important,Very Important,Very Important,Very Important,Very Important,Slightly Important,Very Important,Slightly Important,,"Yes, I'd attend",Yes,"Documentation, Slack",Monthly,Probably,Excellent,Excellent,Excellent,Excellent,I want to be able to use it as mechanism to provide third-party libraries to the ESP project that I support and with the required compilers and options not provided by the facility by default.,The Slack channel is useful and the documentation is very useful too.,,"1) Keep doing outreach efforts, videos, tutorials, hackathons, whatever to spread the voice more. It is very useful to listen to presentations to have features and functionality ""printed"" in our memory. 2) If you happen to read this and you are interested in learning more about Uintah and have a discussion about its potential addition to Spack, please don't hesitate to contact me.","I would like to be able to contribute one day adding the Uintah software suite (http://uintah.utah.edu). I'm ALCF catalyst for their ESP project and I'm learning how to use it and helping them with porting efforts for Aurora. Maybe one day we could add it to Spack. Specially, because Uintah is a code that had invested years, and years, and multiple Ph.D. students to add a real performance portability layer.",You are all doing an excellent job!
11/17/2020 19:49:42,System Administrator,University HPC/Computing Center,United States,No,Traditional HPC / Simulation,Word of mouth,0,"Slack Discussions, Issues",0.15,Red Hat,"500-1,000",3.6,Do it!,Do it!,Environment Modules (TCL modules),"Environments, Module generation, Stacks (matrices in environments), build-env (debug a build), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml",Intel,NVIDIA,"gcc, Intel Compilers, nvcc",Very Important,Critical,Very Important,Slightly Important,Not Important,Somewhat important,Somewhat important,Very Important,Somewhat important,Slightly Important,Very Important,Not Important,,"Yes, I'd attend",Yes,"Documentation, Slack",Daily,Probably,Excellent,Good,OK,Good,"I am using Spack to build the software environment for our users on our University's centralized HPC system.

Outside of Spack, I first built 4 versions of the GNU compilers and installed 2 versions of Intel PSXE and then subsequently built OpenMPI for each of the 6 compiler toolchains mentioned. These packages are available via modulefiles; I split up the Intel PSXE into its various components (compilers, MPI, MKL, TBB, DAAL, etc.). These are available to Spack and the users as a ""base toolchain"" set.

Spack is configured to work exclusively with these modulefiles, which has three primary benefits:
1. Spack will use a ""known-good"" base toolchain as its starting point, including site-specific versions of OpenMPI, etc.
2. It is safe to uninstall everything or start fresh within Spack, since the base toolchain is isolated.
3. This cuts down tremendously on the time required for running the first few Spack builds.
Even though I also dabbled with 'spack external find' with good success, I ultimately opted for not using too many system packages within Spack. We are going to move to rhel8/centos8 within the next year, and I don't want to have to manage two totally different and incompatible configurations.

I maintain several configuration sets (profiles) in a git repo. These contain the five main configuration files (config, compilers, packages, modules, and mirrors). I first experimented with custom scopes, but this was not friendly to many of the built-in shell functions. I simply symlink the profile I want to my ~/.spack directory; the downside to this approach is that only one profile can be active at a time.

Once everything was configured correctly within Spack, I created a single environment that builds the master software stack. Any package that needs to get added or removed should be done so within that environment, and never installed directly. I also create environments for individual applications that I am working on that may not be available in Spack yet. I use these environments to create views to use during build-time, and to test the modulefiles that will be eventually loaded by the users at run-time.","High quality recipes and good configuration options make Spack incredibly flexible and robusy for producing consistent software installations. This has drastically reduced the time spent on compiling dependencies, and has also allowed me to use a more consistent toolchain across all builds.","Some package recipes need improvements but there are often no maintainers available to do quick review.

We need better configuration management -- custom scopes are not well integrated into the Spack shell functions which are crucial for smooth operation.

Better parallel building of environments. I think Slurm integration could be very good to have beyond the basic 'srun -N 2 -n  8 spack install -j  4 <package>' functionality.
",I know that some sysadmin/configuration management stuff is in the pipeline for this year which would make a huge difference for me.,"abinit 9, charmm, wien2k, vasp, povray, wrf, cesm2",Keep up the good work. I will continue using and supporting Spack for many years to come.
11/17/2020 19:50:43,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,No,Computer Science Research,Word of mouth,3,"Packages, Slack Discussions, Issues","0.15, develop","macOS, Red Hat, Ubuntu","> 1,000","2.7, 3.7",Do it!,I'd live (I can provide Python 3 somehow),"spack load, Spack environments","Environments, Chaining, Stacks (matrices in environments), build-env (debug a build), Externals in packages.yaml, Concretization preferences in packages.yaml, spack ci (generate GitLab Pipelines)","AMD, Intel, IBM Power, ARM","NVIDIA, AMD","gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc, XL",Critical,Somewhat important,Critical,Somewhat important,Very Important,Critical,Very Important,Very Important,Very Important,Very Important,Somewhat important,Slightly Important,,"Yes, I'd attend",Yes,"Documentation, Slack, Coworkers",Weekly,No,Good,Excellent,Good,Good,Install project dependencies for development or testing.,Automation/reproducibility of installations.,Spack scopes when multiples instances of Spack. Requires extensive knowledge to be used and solve issues.,Speed-up and ease spack use: optimized workflow for development and testing.,,
11/17/2020 19:51:24,Software Developer,Other Public Research Lab,United States,Yes,Computer Science Research,Used at my site,1,"Packages, Core Features, Slack Discussions, Issues","0.15, develop","Red Hat, CentOS, Ubuntu","> 1,000","3.6, 3.7",Do it!,Do it!,"spack load, Spack environments","Environments, Binary Caches, spack-python (Python scripting), Externals in packages.yaml, Concretization preferences in packages.yaml, spack ci (generate GitLab Pipelines)","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, LLVM, AMD hipclang, nvcc, XL, CCE (Cray Compilers)",Very Important,Very Important,Very Important,Somewhat important,Very Important,Somewhat important,Somewhat important,Somewhat important,Very Important,Very Important,Somewhat important,Slightly Important,general ability to add metadata to individual cached packages,"Yes, I'd attend",Yes,"Documentation, Slack, Coworkers",Monthly,Probably not,Good,Excellent,Good,Good,,,,,,
11/17/2020 19:52:01,Scientist/Researcher,University HPC/Computing Center,Czech Republic,No,Traditional HPC / Simulation,Used at my site,3,"Packages, Issues",0.15,Ubuntu,10 - 100,2.7,Do it!,Do it!,Lmod,"Environments, Module generation, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, LLVM",Very Important,Very Important,Very Important,Not Important,Not Important,Slightly Important,Slightly Important,Slightly Important,Slightly Important,Slightly Important,Somewhat important,Not Important,faster concretization,"Yes, I'd attend",No,"Documentation, Mailing List",Weekly,Probably not,Good,Excellent,Good,Good,,,,,,
11/17/2020 19:52:52,System Administrator,University HPC/Computing Center,United States,No,"Traditional HPC / Simulation, Statistics / Data Analysis, AI/ML, Bioinformatics",Birds-of-a-feather (BOF) at conference,0,No,0.13,CentOS,10 - 100,3.5,I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),Lmod,Module generation,"AMD, Intel",NVIDIA,"gcc, Intel Compilers, nvcc",Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,,"Yes, I'd attend",Yes,"Documentation, Mailing List",Monthly,Probably,OK,OK,OK,OK,I quit testing it because it was harder than our current workflow,I went back to old way,"set up, and when a dependency fails (has not been updated)",Easier to set up,,
11/17/2020 19:53:41,Scientist/Researcher,Company,United States,No,"Traditional HPC / Simulation, AI/ML",Tutorial,4,No,"0.13, 0.14, 0.15","Red Hat, CentOS, Ubuntu","500-1,000","2.7, 3.6, 3.7",I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),"spack load, Lmod, Environment Modules (TCL modules)","Environments, Module generation, spack external find, Externals in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD","gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc, XL, armclang",Very Important,Critical,Very Important,Very Important,Very Important,Somewhat important,Somewhat important,Slightly Important,Very Important,Not Important,Critical,Not Important,"1) An easy way to upgrade all packages (with the closest choice of same options used before) without using environments.
2) Native support for other compilers (AMD hipcc, aocc, Mentor Graphics etc.)","Yes, I'd attend",Yes,"Documentation, Slack",Weekly,Probably not,Good,Good,Good,Good,Providing a more complete development environment for internal research systems,Being able to bring up an up2date dev environment quickly and consistently,"1) Packages that fail to build for some obscure error - usually on a slightly different O/S. I still have to get to build all of xsdk on all my platforms.
2) Having to trick Spack to use a specific package version despite Spack insisting on using a close relative of it in terms of build options (that needs to be installed). In the end I end up with multiple almost identical copies of OpenMPI, HDF5 etc.",,,Spack is a great idea - unfortunately right now it can be both a life-saver and an enormous headache.
11/17/2020 20:09:20,System Administrator,University HPC/Computing Center,United States,No,"Traditional HPC / Simulation, Statistics / Data Analysis, AI/ML, Bioinformatics, High Energy Physics",Birds-of-a-feather (BOF) at conference,1,"Packages, Issues",0.14,Red Hat,200 - 500,"2.7, 3.6",I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),Environment Modules (TCL modules),"Environments, Externals in packages.yaml, Concretization preferences in packages.yaml, json output of spec and find","AMD, Intel",NVIDIA,"gcc, Intel Compilers, PGI, LLVM, nvcc",Somewhat important,Somewhat important,Slightly Important,Not Important,Not Important,Somewhat important,Somewhat important,Slightly Important,Somewhat important,Not Important,Somewhat important,Slightly Important,include files in environments; improved diagnositics for concretization issues,Maybe,Yes,"Documentation, Mailing List",Weekly,Probably not,Excellent,Good,Good,Good,"I maintain a software library for users.  Typically install using mutliple environments (e.g. all packges built w specific compiler/MPI combo), and home-grown perl wrappers around spack to ensure package and all non-trivial dependencies are defined in package.yaml and all variants specified. ",It makes building of software packages more efficient as I can leverage work done by others in working out issues with package installations.,"every now and then I get a package which has errors when concretizing spec in my environment.  While these are generally issues in my configuration clashing with package requirements, it can be very hit or miss to diagnose why.  E.g. https://groups.google.com/g/spack/c/TfHNKHvc_Q4.  It would be nice if debug messages could be improved to help explain why concretizer is making certain decisions/",,,
11/17/2020 20:10:06,Software Developer,University HPC/Computing Center,Germany,No,Traditional HPC / Simulation,Word of mouth,2,"Packages, Issues","0.15, develop","macOS, CentOS, Ubuntu",10 - 100,"2.7, 3.5, 3.7",Do it!,Do it!,"Spack environments, Environment Modules (TCL modules)","Environments, Module generation, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, Intel","gcc, Intel Compilers",Somewhat important,Slightly Important,Slightly Important,Not Important,Somewhat important,Very Important,Somewhat important,Very Important,Slightly Important,Not Important,Slightly Important,Not Important,More documentation on HPC system administration with spack,"Yes, I'd attend",Yes,Documentation,Monthly,Probably not,Good,Good,Excellent,Excellent,,Not requiring root access to install packages,,,,
11/17/2020 20:10:54,Scientist/Researcher,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,"Traditional HPC / Simulation, Computer Science Research, Compiler Testing",Presentation,2,Issues,develop,"macOS, Red Hat, CentOS, Ubuntu","500-1,000","2.6, 2.7, 3.5, 3.6, 3.7",I'd live.  (I can provide 2.7 somehow),Unacceptable,"Lmod, Environment Modules (TCL modules)","Environments, Module generation, Stacks (matrices in environments), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc, XL, CCE (Cray Compilers), Fujitsu Compilers, armclang",Somewhat important,Critical,Very Important,Slightly Important,Somewhat important,Somewhat important,Slightly Important,Slightly Important,Very Important,Not Important,Very Important,Not Important,Faster build times,Maybe,Yes,"Documentation, Mailing List, Coworkers",Monthly,Probably not,OK,Good,Good,Good,,,,,,
11/17/2020 22:05:02,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,No,Traditional HPC / Simulation,Word of mouth,5,Packages,develop,"TOSS, Red Hat",10 - 100,2.7,Do it!,I'd live (I can provide Python 3 somehow),,"build-env (debug a build), Externals in packages.yaml","AMD, Intel, IBM Power","NVIDIA, AMD","gcc, Intel Compilers, LLVM, AMD aocc, AMD hipclang, nvcc",Somewhat important,Somewhat important,Somewhat important,Not Important,Very Important,Somewhat important,Not Important,Critical,Somewhat important,Not Important,Very Important,Not Important,CI Regression Testing of Package Installs on develop branch at LC and other HPC Centers,No,Yes,"Documentation, Coworkers",Yearly,Probably,Good,Good,Bad,OK,,,,,,
11/17/2020 20:13:30,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,No,Traditional HPC / Simulation,Word of mouth,1,No,0.14,"Red Hat, Ubuntu",100 - 200,2.7,I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),spack load,Externals in packages.yaml,"AMD, Intel, IBM Power, ARM","NVIDIA, AMD","gcc, LLVM, AMD hipclang, nvcc",Critical,Very Important,Very Important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Mostly the backtracking concretizer is what would make my life easier,Maybe,Yes,"Documentation, Slack",Monthly,Probably not,Good,Good,OK,Good,,,,,,
11/17/2020 22:02:27,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,Traditional HPC / Simulation,Word of mouth,5,"Packages, Slack Discussions","develop, custom fork","macOS, Red Hat, CentOS, Ubuntu","500-1,000","2.7, 3.6, 3.7, 3.8",I'd live.  (I can provide 2.7 somehow),Unacceptable,Custom script or env vars,"Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, LLVM, AMD hipclang, nvcc, XL, CCE (Cray Compilers)",Very Important,Somewhat important,Somewhat important,Slightly Important,Slightly Important,Very Important,Very Important,Critical,Slightly Important,Not Important,Somewhat important,Slightly Important,focus on simplified use by non-expert spack users,"Yes, I'd attend",Yes,Slack,Yearly,No,Good,Good,OK,OK,,"helps as part of our effort to revision control and automate our process to deploy builds across several HPC sites. Spack is a key component, without this spack it would be impossible for a small team to support users across multiple HPC sites. ",not having continuous testing for package updates,Simplifying use of spack for non experts.,,
11/17/2020 20:16:25,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,"Traditional HPC / Simulation, Computer Science Research, Compiler Testing",Word of mouth,3,"Packages, Slack Discussions, Issues","0.15, develop","macOS, Red Hat, CentOS, Ubuntu, Debian, Fedora",200 - 500,"2.7, 3.8",Do it!,I'd live (I can provide Python 3 somehow),"Lmod, Environment Modules (TCL modules)","Environments, Module generation, Chaining, build-env (debug a build), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, PGI, NVIDIA Compilers (new PGI), LLVM, AMD hipclang, nvcc, XL, CCE (Cray Compilers)",Very Important,Slightly Important,Very Important,Not Important,Not Important,Somewhat important,Slightly Important,Very Important,Critical,Not Important,Very Important,Not Important,,Maybe,Yes,"Documentation, Slack, Coworkers",Weekly,Probably,Bad,Good,Good,Good,,,,,,
11/17/2020 22:03:15,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,Traditional HPC / Simulation,Used at my site,4,"Packages, Documentation, Issues",develop,"macOS, Red Hat, Ubuntu",1 - 10,"2.6, 2.7, 3.5, 3.6",I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),Custom script or env vars,"Command Extensions, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power","NVIDIA, AMD","gcc, Intel Compilers, PGI, LLVM",Very Important,Somewhat important,Somewhat important,Not Important,Very Important,Somewhat important,Somewhat important,Somewhat important,Slightly Important,Not Important,Somewhat important,Very Important,better support for statically linked libs,Maybe,No,"Documentation, Coworkers, GitHub",Monthly,Probably not,Good,OK,OK,Good,,Automated builds of dependencies.,,I'd like to see complete support for static builds.,,"I've felt that Spack started with HPC-centric view of the world to enable robust builds of HPC relevant software stacks on various LCFs. But, as a package manager, it works for a lot of non-HPC stuff and wound up getting somewhat overtaken by a large influx of stakeholders with different interests. I feel like those non-HPC interest often dictate outcomes on major issues. I guess I am saying that to some extent, Spack is a victim of its own success.

I also feel like I expect Spack to be able to behave largely as I would when building a software stack on a given LCF and easily utilize existing ""system"" packages already deployed there either by hardware vendor or facilities managers. But, that never seems to be the way Spack behaves by default. It winds up building the every last dependency for one strange reason or another even though a slew of libraries below say HDF5 in the dependency chain don't need to be re-built. Getting it to behave as I would (e.g. make the same choices w.r.t. to utilizing existing software on a system) is incredibly challenging.

I know plenty of code teams that use Spack for automating builds of their dependencies and it is a godsend for that. I don't know too many though that are truly happy with it or that are not constantly fighting with it to not go build some dependency they don't care about or when they update packages having to unravel some odd-ball package change that is breaking their builds.

In theory, it should be possible for Spack to build VisIt with a package.py file. However, the VisIt project already has code to build it and all of its dependencies and a) it works in many places b) doesn't including build logic for dependencies we don't care about and c) doesn't constantly change/break as one package somewhere in the dependency chain is updated in some odd-ball way. In order for VisIt to want to dump its custom shell code and replace it with a Spack package.py file, the challenges of that experience needs to be addressed somehow. Perhaps the way the CEED project is using Spack to manage their dependencies is one of the best options."
11/17/2020 20:20:36,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,"Traditional HPC / Simulation, Computer Science Research",Word of mouth,3,"Packages, Issues","0.15, develop","macOS, Red Hat",10 - 100,3.8,Do it!,Do it!,"spack load, Lmod","Module generation, build-env (debug a build), spack-python (Python scripting)","AMD, Intel, IBM Power, ARM","NVIDIA, AMD","gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc, CCE (Cray Compilers)",Very Important,Somewhat important,Very Important,Slightly Important,Not Important,Somewhat important,Very Important,Somewhat important,Very Important,Slightly Important,Somewhat important,Slightly Important,,"Yes, I'd attend",Yes,"Documentation, Mailing List",Weekly,Probably,Good,Good,Good,Excellent,,,,,,
11/17/2020 20:21:38,Software Developer,Company,United States,No,Embedded Systems,Used at my site,2,No,develop,"Red Hat, CentOS",10 - 100,3.8,Do it!,I'd live (I can provide Python 3 somehow),"spack load, Spack environments","Environments, Module generation, spack containerize, Chaining, Binary Caches, spack ci (generate GitLab Pipelines), Distributed Builds (srun spack install)","AMD, Intel, IBM Power, ARM",NVIDIA,"gcc, LLVM, nvcc",Slightly Important,Somewhat important,Slightly Important,Somewhat important,Very Important,Slightly Important,Slightly Important,Not Important,Not Important,Not Important,Slightly Important,Critical,"Support for a collaborative binary cache without assuming a network file system, i.e. support for binary packages","Yes, I'd attend",No,Documentation,Weekly,Probably,OK,Excellent,Good,Excellent,Building an ensemble of cross compiled applications that run on a set of coordinating (heterogeneous) embedded devices.,Dependency specs and global concretization have eliminated a tremendous amount of toil,,(Continue to) engage with the wider developed community outside HPC. Just the CppCon lightning talk this year has done a lot to legitimize spack as a viable (and even preferable) alternative to Jfrog's Conan.,,You're awesome
11/17/2020 20:23:02,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,Traditional HPC / Simulation,Used at my site,3,"Packages, Slack Discussions",develop,"macOS, Red Hat, Ubuntu, Windows Subsystem for Linux (WSL)",200 - 500,"3.5, 3.6, 3.7",Do it!,Do it!,"spack load, Spack environments","Environments, Module generation, build-env (debug a build), Python extensions (link python packages into interpreter prefix), spack external find, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc, XL, CCE (Cray Compilers), Fujitsu Compilers, armclang",Somewhat important,Critical,Somewhat important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Somewhat important,Not Important,,No,Yes,"Documentation, Slack",Monthly,Probably not,Good,Excellent,OK,Excellent,"I work on a bunch of testbeds with... whimsical variance in developer environments. Just having a Spack environment that has my compilers and neovim stack, and starting on a new environment by telling Spack to set it up for me to insulate me from that creativity, that's a huge win.

Also people's Spack packages tend to be a lot easier to decipher than their build systems, so `spack info [foo]` and `spack graph [foo]` are hugely useful commands to just know what software does","Greg Becker responding to my questions on Slack. Being able to tell users who ask me how a thing is built ""have you tried building it with Spack?"" The increasing frequency with which `spack install FOO` leads to a successful build of FOO.",Terribly set up machines that block Spack from being able to use CURL,"The complaint I still have to field from people is ""I tried to build a simple package, and Spack built Python and CMake and and and and..."" so I think better deciphering of externals (which I know you're working on as we speak) would be good.",,"Pretty much every year my biggest victory with Spack is ""they fixed the thing that was biggest gripe about Spack last year,"" which is a sign of a really good job listening to users, so keep that up."
11/17/2020 21:50:56,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,Traditional HPC / Simulation,Used at my site,2,No,Not sure. ,"Red Hat, Windows Subsystem for Linux (WSL)",10 - 100,3.7,Do it!,I'd live (I can provide Python 3 somehow),Custom script or env vars,Not sure.,"AMD, Intel, IBM Power","NVIDIA, AMD","gcc, Intel Compilers, LLVM, AMD hipclang, nvcc, XL, CCE (Cray Compilers)",Somewhat important,Very Important,Very Important,Somewhat important,Very Important,Very Important,Somewhat important,Somewhat important,Somewhat important,Very Important,Critical,Very Important,,Maybe,No,Coworkers,Never,Probably not,OK,OK,OK,OK,"I am a developer on the Axom library.  We have a set of third-party libraries that we want to be fixed at certain versions.  We use Uberenv, a set of Python scripts, to make it so that all a user has to do is run one command

python uberenv.py

to produce a set of TPLs.  On Linux and Mac OS, this configures and drives spack; on Windows, Uberenv drives vcpkg to the same end.",,,"Make Spack easy to use, and support Windows.",,
11/17/2020 22:04:03,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,No,Traditional HPC / Simulation,Presentation,2,Packages,develop,"macOS, Red Hat, Ubuntu",10 - 100,2.7,I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),Custom script or env vars,Externals in packages.yaml,"AMD, Intel, IBM Power","NVIDIA, AMD","gcc, Intel Compilers, LLVM, AMD aocc, nvcc, XL, CCE (Cray Compilers)",Somewhat important,Very Important,Somewhat important,Not Important,Very Important,Critical,Very Important,Somewhat important,Very Important,Not Important,Critical,Somewhat important,,Maybe,No,"Documentation, Coworkers",Yearly,Probably not,Good,Excellent,Good,Good,,,,,,
11/17/2020 21:45:51,Software Developer,Company,United States,No,"Traditional HPC / Simulation, AI/ML",Search,0,No,0.15,"Red Hat, CentOS",1 - 10,3.5,Do it!,Do it!,Spack environments,"Environments, spack ci (generate GitLab Pipelines)","Intel, ARM",NVIDIA,"gcc, NVIDIA Compilers (new PGI), LLVM, nvcc",Critical,Slightly Important,Somewhat important,Not Important,Not Important,Slightly Important,Not Important,Not Important,Somewhat important,Not Important,Critical,Somewhat important,Cross compiler support ,Maybe,No,"Documentation, Slack",Monthly,Probably not,Good,Excellent,Excellent,Excellent,,Environments ,,"Cross compiler support, new concreteizer",,
11/17/2020 20:27:17,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,Traditional HPC / Simulation,Used at my site,4,Packages,develop,"macOS, Red Hat",10 - 100,"3.7, 3.8",Do it!,Do it!,"spack load, Spack environments, Lmod","Environments, Module generation, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, PGI, LLVM, XL, CCE (Cray Compilers)",Critical,Slightly Important,Slightly Important,Not Important,Not Important,Slightly Important,Somewhat important,Not Important,Somewhat important,Slightly Important,Slightly Important,Not Important,Better concretizer wrt to compiler selection,Maybe,Yes,"Documentation, Slack, Coworkers",Monthly,"Yes, definitely!",Excellent,Excellent,OK,Good,development / complex dependency management,Greg Becker,concretizer’s selection of compiler,magic new concretizer,,keep up the great work!
11/17/2020 20:27:59,Scientist/Researcher,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,Computer Science Research,Used at my site,0,No,0.15,"macOS, Red Hat",1 - 10,3.8,Do it!,Do it!,spack load,"spack-python (Python scripting), Command Extensions, Python extensions (link python packages into interpreter prefix), spack external find, Concretization preferences in packages.yaml","AMD, Intel","NVIDIA, AMD","gcc, LLVM, AMD hipclang, nvcc",Somewhat important,Somewhat important,Slightly Important,Not Important,Very Important,Very Important,Very Important,Slightly Important,Very Important,Somewhat important,Very Important,Not Important,Better interaction with/support to build Python packages,"Yes, I'd attend",Yes,Documentation,Monthly,"Yes, definitely!",Good,OK,OK,Excellent,"Install hwloc, MPI, etc. on my Mac; build recipes for my own software. ",Being able to use HPC packages on my Mac,,Better interaction with Python packages,,Please keep up the good work. Thank you!
11/17/2020 20:29:04,Scientist/Researcher,University HPC/Computing Center,United States,Yes,"Traditional HPC / Simulation, Computer Science Research, Compiler Testing",Presentation,1,Packages,develop,"macOS, Red Hat, CentOS, Ubuntu, SuSE, Gentoo",100 - 200,"3.6, 3.7, 3.8",I'd live.  (I can provide 2.7 somehow),Do it!,"spack load, Spack environments","Environments, Chaining, Stacks (matrices in environments), Binary Caches, build-env (debug a build), Python extensions (link python packages into interpreter prefix), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml, Distributed Builds (srun spack install), Repositories","Intel, IBM Power","NVIDIA, Intel","gcc, Intel OneAPI / dpc++, NVIDIA Compilers (new PGI), LLVM, nvcc",Somewhat important,Somewhat important,Slightly Important,Not Important,Slightly Important,Very Important,Very Important,Somewhat important,Critical,Very Important,Very Important,Not Important,Languages/compilers as virtual dependencies!,Maybe,No,"Documentation, Slack",Weekly,No,Excellent,Excellent,Good,Excellent,"I write a software package for the CODAR project within ECP which has >20 dependencies, and using spack has substantially cut down on the effort to get new users started and migrate experiments from machine to machine. I eagerly look forward to when I can use spack for my entire development workflow including debugging and testing with debuggers, sanitizers, and linters. ",Combinatorial versioning for the win!! Environments are great too!,"Two big ones:
Not having language virtual dependencies makes it harder to have language polyfills for newer features when the compiler doesn’t support them. It also is hard to say what compiler versions you support

Better Debug builds. Specifically making it easy to get a stack trace with meaningful symbols in GDB would be amazing since by default the source files are not where GDB looks for them and/or are deleted by default.

Two ill-defined nice to haves:
Right now, if I create a package with spack, I almost have to maintain three things separately: the code and build system, the spack package , and the spack environment and lock file  for users to use as a development environment. It would be nice to cut down on the duplication here if possible (it might not be).

Updating packages feels more painful than it could be. Specifically I’d like to be able to update a specific package in an environment holding as much constant as possible, and right now I’m unsure how to best do that. ",Language virtual dependency ,,Keep being awesome! Spack is my favorite tool of the last 5 years!
11/17/2020 20:29:39,System Administrator,University HPC/Computing Center,Argentina,No,Traditional HPC / Simulation,Word of mouth,3,Packages,develop,"CentOS, Ubuntu",10 - 100,"2.6, 2.7",I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),Environment Modules (TCL modules),Externals in packages.yaml,"AMD, Intel",NVIDIA,"gcc, Intel Compilers, Intel OneAPI / dpc++, NVIDIA Compilers (new PGI), LLVM, AMD aocc, nvcc",Somewhat important,Very Important,Slightly Important,Not Important,Very Important,Somewhat important,Very Important,Slightly Important,Somewhat important,Slightly Important,Very Important,Not Important,,Maybe,Yes,Documentation,Monthly,No,Good,Good,OK,Good,,,,,,
11/17/2020 21:52:08,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,Traditional HPC / Simulation,Search,0,No,Do not know,Red Hat,1 - 10,"3.5, 3.6, 3.7, 3.8",Do it!,Do it!,Lmod,,"AMD, Intel, IBM Power","NVIDIA, AMD","gcc, Intel Compilers, NVIDIA Compilers (new PGI), LLVM, AMD hipclang, XL",Very Important,Very Important,Very Important,Not Important,Very Important,Very Important,Very Important,Very Important,Very Important,Not Important,Critical,Not Important,,"Yes, I'd attend",No,"Documentation, Slack",Yearly,No,OK,Horrible,Bad,Bad,I'm trying to learn how I can use it,Hoping it could ease building different configurations,Does not work as promised,"Dedicate experts to resolves issues and answer questions on slack, other forums",,
11/17/2020 20:32:11,Software Developer,Company,United States,No,Traditional HPC / Simulation,Word of mouth,5,Packages,develop,"Red Hat, CentOS, Ubuntu, Debian, Fedora",100 - 200,3.8,Do it!,Do it!,Lmod,"Environments, Module generation, Externals in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD","gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, XL, CCE (Cray Compilers)",Somewhat important,Slightly Important,Somewhat important,Slightly Important,Slightly Important,Somewhat important,Somewhat important,Somewhat important,Slightly Important,Slightly Important,Somewhat important,Not Important,,"Yes, I'd attend",Yes,"Slack, Mailing List",Weekly,Probably not,Good,Good,Good,Good,,,,,,
11/17/2020 20:32:49,Software Developer,Other Public Research Lab,Italy,No,Traditional HPC / Simulation,Word of mouth,2,"Packages, Issues",0.13,"Red Hat, CentOS","500-1,000","3.5, 3.6",Do it!,Do it!,"Spack environments, Environment Modules (TCL modules)","Environments, Module generation, Chaining, build-env (debug a build), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, Intel Compilers, LLVM",Somewhat important,Somewhat important,Very Important,Slightly Important,Slightly Important,Very Important,Somewhat important,Somewhat important,Very Important,Not Important,Very Important,Not Important,,"Yes, I'd attend",Yes,"Documentation, Coworkers",Monthly,Probably not,Good,Good,Excellent,Excellent,"We deploy a complex sw stack on different HPC clusters, using spack as internal engine. Lot of environments stuff, lot of custom packages for customer code. At runtime, we use generated tcl modules.","Huge help in deploy complex and large  sw stacks, before spack we used and internal tool with lots of quirks, that spack resolved quickly. Good documentation and community support",Virtual packages and providers,Better develop workflow,,
11/17/2020 20:35:01,Scientist/Researcher,Other Public Research Lab,Germany,No,"Traditional HPC / Simulation, Computer Science Research",Word of mouth,3,"Packages, Core Features, Issues","0.12, develop","macOS, Ubuntu, Windows Subsystem for Linux (WSL)",10 - 100,"2.7, 3.7, 3.8",Do it!,Unacceptable,"Spack environments, Containers","Environments, build-env (debug a build), Python extensions (link python packages into interpreter prefix), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, ARM",NVIDIA,"gcc, LLVM, nvcc",Critical,Not Important,Slightly Important,Not Important,Somewhat important,Very Important,Somewhat important,Slightly Important,Slightly Important,Slightly Important,Very Important,Very Important,better concretisation error reporting (i.e. hints where the error originated),"Yes, I'd present something!",No,"Documentation, Coworkers, GitHub",Monthly,Probably not,OK,Excellent,Good,Good,"Doing the sci-python installation on my Mac with it, but mostly b/c we build our containers in the lab with spack. We have a couple of meta-packages (that should be converted to environments, but who's got time for that) that we build and expose via dedicated spack view's. This gets than packaged to a singularity container and allows us to ship our software to any site we run.",not worrying about whether the rebuild of my software will work. Environments are nice too,"concretisation time and error reporting, but this may be because we are on a (maybe) year old fork, updating is a bit of a pain as we use a different binary-cache implementation (we know in advance where our packages will end up and therefore don't want to spend the time rewriting the strings. Not sure if this is upstream able though)","fix fortran support on Mac
>  microarchitecture specific optimizations are not supported yet on mixed compiler toolchains [check apple-clang@12.0.0 for further details]","no, and I think adding packages is sufficiently easy, automatically digest packages published on other package managers would be useful though (e.g. pypi -> python package automatisation for the ""nothing special needed packages"")",
11/17/2020 22:12:54,Scientist/Researcher,Other Public Research Lab,Germany,No,Traditional HPC / Simulation,Technical Paper,4,"Packages, Core Features, Documentation, Slack Discussions, Issues",develop,"macOS, Red Hat, Ubuntu",200 - 500,"2.7, 3.6, 3.7",Unacceptable  (it's the only python on important machines),Unacceptable,"spack load, Environment Modules (TCL modules)","Module generation, build-env (debug a build), Python extensions (link python packages into interpreter prefix), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, nvcc, NAG, CCE (Cray Compilers)",Critical,Very Important,Very Important,Not Important,Not Important,Slightly Important,Somewhat important,Slightly Important,Somewhat important,Not Important,Somewhat important,Not Important,More transparent and predictable handling of preferences and externals in packages.yaml.,Maybe,No,"Documentation, Slack, Source Code",Weekly,Probably not,Good,Excellent,Good,Excellent,,,,,,
11/17/2020 20:36:25,Software Developer,Company,France,No,"Computer Science Research, Compiler Testing",Word of mouth,3,Packages,develop,"macOS, CentOS, Debian",100 - 200,3.7,Do it!,Do it!,"spack load, Environment Modules (TCL modules)",Module generation,"Intel, ARM",NVIDIA,"gcc, LLVM, nvcc",Very Important,Very Important,Somewhat important,Not Important,Slightly Important,Somewhat important,Not Important,Very Important,Critical,Critical,Very Important,Not Important,,"Yes, I'd attend",Yes,"Documentation, Coworkers",Weekly,Probably not,Good,OK,Good,Good,Used in a daily basis to manage my own software stack in multiple environments. Also used to freeze a group of packages required by in-dev projects,Its ability to support a large panel of softwares,"Currently, no support for installing & using a fresh compiler in the same workflow. This may be the solution to some scenarios requiring to install and use a patched compiler in a single command (""spack install"")",,,
11/17/2020 20:37:11,System Administrator,Cloud Provider,Czech Republic,No,"AI/ML, Bioinformatics, High Energy Physics",Presentation,1,"Mailing List, Issues",0.15,"CentOS, Debian",100 - 200,2.7,Do it!,I'd live (I can provide Python 3 somehow),Environment Modules (TCL modules),"Environments, Module generation, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, Intel Compilers, AMD aocc",Somewhat important,Very Important,Very Important,Not Important,Not Important,Slightly Important,Slightly Important,Not Important,Somewhat important,Not Important,Slightly Important,Not Important,"support for ""holding a package"" - some extra protection for package against being deleted or renamed (re-hashed)","Yes, I'd attend",No,"Documentation, Mailing List, Coworkers",Daily,Probably,OK,Good,Good,OK,"Installing SW in central storage for Debian and Centos systems using various compilers depending on optimization needs and ability of the package building with certain compiler. Use mainly Intel (and AOCC in future), if it's not supported by SW, use GCC.",Documentation and forum,too little aggressiveness of re-using already installed packages and so re-hashing packages for every version of spack,,"wien2k, molpro, (cs)rosetta, geneious, ansys (+fluent+cfx+mechanical+hpc)","Good work, guys :) Well but why you ask about python version for running spack when spack itself is dependent on the python in environment? (https://groups.google.com/g/spack/c/RBzLouf-vGA/m/ovUKkyMUAgAJ) . I'd budled spack with some version of python suiting it's needs and then fix it to use only that if possible. Otherwise you would still have to deal with many versions of python..."
11/17/2020 20:37:48,Scientist/Researcher,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,Traditional HPC / Simulation,Used at my site,2,"Packages, Core Features, Slack Discussions",develop,"macOS, Red Hat",200 - 500,"2.7, 3.6, 3.7, 3.8",Do it!,I'd live (I can provide Python 3 somehow),spack load,"Environments, Binary Caches, build-env (debug a build), Command Extensions, Externals in packages.yaml, Concretization preferences in packages.yaml, Distributed Builds (srun spack install)","AMD, Intel, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, NVIDIA Compilers (new PGI), LLVM, nvcc",Very Important,Very Important,Critical,Not Important,Slightly Important,Very Important,Critical,Somewhat important,Not Important,Slightly Important,Very Important,Not Important,"Specify where user config settings live (not ~/.space), parallelization of the DAG with verbose notifications of the packages being built simultaneously, ability to specify any flags we want on all the time when running spack commands in the config file (—verbose for install, -n for dev-build, etc)","Yes, I'd attend",No,"Documentation, Slack, Coworkers",Weekly,Probably not,OK,OK,OK,Good,Develop and deploy software. I try to use spack for my deployed software and I use it to establish my TPL’s for development. Currently evaluating dev-build but have a few gripes with it. Also working on a unified cache of TPL’s for developers site wide. ,,Spack rebuilding packages that don’t need to be rebuilt due to change in concretization or some other mystery. ,Clean up Cuda and nvcc-wrapper stuff. Find ways to minimize unnecessary dependency rebuilds. ,,It would be nice to have some guidelines of what to post on slack vs feature request/GitHub issue. I feel like my posts on slack have been getting ignored lately but there are so many PR’s and GitHub issues that I expect they will just be lost in the noise there too. Maybe some insight into how GitHub issues are triaged and responded to by the core developers?
11/17/2020 20:38:23,Software Developer,University HPC/Computing Center,United States,Yes,"Traditional HPC / Simulation, Computer Science Research",Birds-of-a-feather (BOF) at conference,2,Packages,develop,"macOS, Red Hat, CentOS, Ubuntu, Debian, Fedora",10 - 100,"3.6, 3.7, 3.8",Do it!,Do it!,"spack load, Spack environments, Environment Modules (TCL modules)","Environments, Module generation, build-env (debug a build), spack external find","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, XL, CCE (Cray Compilers), Fujitsu Compilers",Somewhat important,Critical,Very Important,Slightly Important,Critical,Somewhat important,Somewhat important,Critical,Very Important,Somewhat important,Critical,Not Important,,Maybe,Yes,"Documentation, Coworkers",Monthly,Probably not,Good,Good,OK,OK,,,,,,
11/17/2020 20:39:04,Scientist/Researcher,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,"Traditional HPC / Simulation, Computer Science Research",Used at my site,2,No,0.15,Red Hat,1 - 10,2.7,I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),Spack environments,"Environments, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD","gcc, Intel Compilers, LLVM, AMD hipclang, nvcc, XL",Not Important,Somewhat important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Very Important,Not Important,Very Important,Not Important,,Maybe,No,Coworkers,Never,No,Bad,Bad,Bad,Bad,"Try to build my app, not getting TPLs built correctly, swear, then build TPLs  manually, try to tell Spack where my manually built TPLs are, swear more, give and use Cmake instead or ask my coworker to fix Spack",My coworker,It does not build and find TPLs correctly,"Explain clearly how to tell Spack to build TPLs and if not possible, how to tell Spack that the TPLs I want are in a given directory",,It's pretty hard to use for developers it does not really help build the TPLs properly so often I need to build the dependencies manually and then try to convince Spack that it is wrong to pick default OS versions of TPLs...
11/17/2020 20:39:40,Software Developer,University HPC/Computing Center,Germany,Yes,Traditional HPC / Simulation,Word of mouth,0,Packages,develop,"Red Hat, CentOS",1 - 10,"3.5, 3.6, 3.7",Do it!,Do it!,"Spack environments, Environment Modules (TCL modules)",Environments,"AMD, Intel, ARM","NVIDIA, AMD","gcc, Intel Compilers, Intel OneAPI / dpc++, LLVM, AMD hipclang, nvcc",Slightly Important,Somewhat important,Very Important,Not Important,Slightly Important,Very Important,Somewhat important,Critical,Very Important,Slightly Important,Critical,Slightly Important,-,"Yes, I'd attend",No,"Documentation, Slack, Coworkers",Monthly,Probably not,Good,Good,OK,Excellent,,,,,,
11/17/2020 22:10:09,Scientist/Researcher,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,"Traditional HPC / Simulation, Statistics / Data Analysis, AI/ML",Word of mouth,2,Issues,develop,"Red Hat, CentOS",100 - 200,"3.7, 3.8",Do it!,Do it!,spack load,none,"AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), LLVM, nvcc, XL, Fujitsu Compilers, armclang",Not Important,Not Important,Somewhat important,Not Important,Not Important,Not Important,Not Important,Slightly Important,Somewhat important,Not Important,Very Important,Not Important,Build packages on an air-gapped system with different arch from the login/fetch nodes.  ,No,No,"Documentation, Source Code",Monthly,No,OK,OK,Bad,OK,maintaining software system for research groups,build software with HPC specific flags,build packages on an air-gapped system.,"Make spack more like nix or guix.  Spack still has many hidden dependencies to the system, which makes the build non-deterministic and impossible to verify.",,"Spack could have started by forking nix or guix or just pkgsrc instead of making its own set of python scripts.  It left a lot of packages for its developers to maintain, and there's just not many maintainers like any of the popular package managers.  If spack could built on top of any popular package managers, it would have started much faster without reinventing the wheel to get all the packages rolling."
11/17/2020 20:41:10,Scientist/Researcher,University HPC/Computing Center,Ireland,No,Traditional HPC / Simulation,Birds-of-a-feather (BOF) at conference,1,No,0.15,"macOS, CentOS",1 - 10,3.7,Do it!,Do it!,Spack environments,"Environments, Module generation, spack containerize, build-env (debug a build)","Intel, ARM",NVIDIA,"gcc, Intel Compilers, LLVM",Not Important,Somewhat important,Somewhat important,Not Important,Very Important,Critical,Somewhat important,Somewhat important,Very Important,Not Important,Somewhat important,Not Important,,Maybe,Yes,Documentation,Daily,Probably not,Bad,OK,OK,OK,,,,"Documentation organisation, examples, and explicit API listing of all internal functionality.",,"The documentation while detailed needs better structure with clearer and more concise examples. I spend a lot of time constantly jumping between pages, and going to the github repo to see how other similar packages are built.

Good when you know how, but ramping on is extremely laborious."
11/17/2020 20:41:59,Scientist/Researcher,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,"Traditional HPC / Simulation, Computer Science Research",Word of mouth,2,No,custom fork,"Red Hat, Ubuntu, Debian",10 - 100,3.6,Do it!,Do it!,Spack environments,"Environments, Binary Caches, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD","gcc, Intel Compilers, LLVM, nvcc, Fujitsu Compilers",Very Important,Somewhat important,Slightly Important,Slightly Important,Very Important,Very Important,Critical,Critical,Somewhat important,Not Important,Not Important,Not Important,I want to demand that packages are cloned by commit id. Spack packages that references branches are not reproducible!,"Yes, I'd present something!",No,"Documentation, Slack, Coworkers",Weekly,No,OK,Excellent,OK,Excellent,"Spack environments defined and checked into a git repo with a Dockerfile. Dockerfile is based on the spack/centos container, spack buidls in Dockerfile script, then setup-env.sh runs in entrypoint at runtime. ",,"Packages that rely on moving target branches are a bad thing for my workflows. Kitware, I'm looking at you....",,,
11/17/2020 20:42:49,Scientist/Researcher,Other Public Research Lab,United States,Yes,"Traditional HPC / Simulation, Statistics / Data Analysis",Used at my site,0,Packages,"0.15, develop","macOS, CentOS",10 - 100,"3.7, 3.8",Do it!,Do it!,"spack load, Environment Modules (TCL modules)","Module generation, build-env (debug a build), Command Extensions, Externals in packages.yaml",Intel,NVIDIA,"gcc, Intel Compilers, LLVM",Somewhat important,Somewhat important,Somewhat important,Not Important,Very Important,Very Important,Somewhat important,Somewhat important,Slightly Important,Slightly Important,Somewhat important,Not Important,,"Yes, I'd attend",Yes,"Documentation, Source Code",Weekly,Probably,OK,Good,Good,Good,,,,Improve package developer documentation (something documenting the python classes a bit better),,
11/17/2020 20:43:42,Software Developer,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,No,Bioinformatics,Used at my site,4,Core Features,develop,SuSE,100 - 200,"2.7, 3.7",Do it!,Do it!,Lmod,"Stacks (matrices in environments), spack-python (Python scripting), Externals in packages.yaml, Concretization preferences in packages.yaml",AMD,NVIDIA,"gcc, PGI, NVIDIA Compilers (new PGI), LLVM, CCE (Cray Compilers)",Critical,Critical,Somewhat important,Not Important,Slightly Important,Somewhat important,Very Important,Somewhat important,Somewhat important,Somewhat important,Critical,Not Important,"Better support with Cray and also have Spack help with cross-compiling. I just want to re-iterate that many complaints have been had about Spack rebuilding an entire stack especially when building for different architectures. So having quick builds is important especially when a site needs to reconstruct their entire software environment. The `packages.yaml` configuration file is suppose to help with this but any little change in the DAG makes spack rebuild these dependencies (cmake, zlib, etc) ",No,Yes,"Documentation, Slack, Coworkers",Monthly,Probably not,Good,Excellent,Good,OK,,,,,,
11/17/2020 20:44:19,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,Traditional HPC / Simulation,Word of mouth,2,"Packages, Core Features, Documentation, Slack Discussions",develop,"macOS, Red Hat, CentOS, Ubuntu, Windows Subsystem for Linux (WSL)",200 - 500,"2.7, 3.7, 3.8",Do it!,Do it!,Spack environments,"Environments, Externals in packages.yaml, Concretization preferences in packages.yaml, Distributed Builds (srun spack install)","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, NVIDIA Compilers (new PGI), LLVM, AMD hipclang, nvcc, XL, CCE (Cray Compilers), armclang",Very Important,Somewhat important,Critical,Not Important,Slightly Important,Somewhat important,Very Important,Slightly Important,Very Important,Not Important,Very Important,Somewhat important,Better Rust+Cargo support! :),Maybe,No,"Documentation, Slack, Coworkers",Weekly,Probably not,Good,Excellent,OK,Excellent,,,"surprising re-concretizations, updating environments and removing old packages",improve performance on shared file systems,,
11/17/2020 20:44:55,User Support Staff,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,"Traditional HPC / Simulation, Compiler Testing",Word of mouth,3,No,develop,SuSE,1 - 10,3.6,Do it!,Do it!,Environment Modules (TCL modules),Externals in packages.yaml,"AMD, Intel",NVIDIA,"gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc, CCE (Cray Compilers)",Somewhat important,Critical,Very Important,Not Important,Somewhat important,Somewhat important,Very Important,Very Important,Somewhat important,Somewhat important,Somewhat important,Not Important,"Separate concretization of applications and build tools (e.g., CMake, tar, gzip, etc.). Just because one wants to build LAMMPS with Intel v19 does not mean that one also wants a new CMake built with Intel v19.",Maybe,Yes,Documentation,Monthly,Probably not,Good,Bad,OK,OK,"I have tried to use Spack to build the handful of applications and libraries that I support for users, like NWChem, LAMMPS, etc. I have tried both letting Spack build the entire application from the ground up (including tar, OpenSSL, ...), and also using `packages.yaml` to fill in as many external installations as possible. These two approaches have had varying levels of success, although build failures continue to be common.","It can be useful for installing packages which have a large number of dependencies, such as HPCToolkit.","The long build times due to starting at such a low level in the software stack is frustrating, as is the inevitable glut of standard system packages built many times over again, like tar, openssl, gzip, CMake, etc. Perhaps the reason for this behavior is driven by a constraint that some system relying on Spack do not have these packages installed already; but as an occasional Spack user, every system I have ever tried to use it on - both workstations and HPC systems - *does* have them installed. So at least having an option for Spack to be a bit more abstemious when it is building a package from the ground up would be very useful.","Make the default behavior to search through /usr/bin, /usr/lib64, and other 'standard' locations to resolve as many external dependencies as possible, before attempting to build anything from scratch. `spack external find` is a step in this direction, but does not seem to solve this problem as completely as it could.",,
11/17/2020 20:45:48,Scientist/Researcher,University HPC/Computing Center,United States,Yes,Traditional HPC / Simulation,Birds-of-a-feather (BOF) at conference,2,"Packages, Documentation, Slack Discussions, Mailing List, Issues",0.15,"macOS, Red Hat, CentOS, Arch",10 - 100,2.7,Do it!,I'd live (I can provide Python 3 somehow),Lmod,"Environments, Module generation, Stacks (matrices in environments), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc",Critical,Very Important,Somewhat important,Not Important,Not Important,Not Important,Not Important,Somewhat important,Slightly Important,Not Important,Slightly Important,Not Important,email client :),"Yes, I'd attend",Yes,"Documentation, Slack",Monthly,Probably not,Good,Excellent,Excellent,Excellent,,fewer build scripts for large/deep software stacks,teaching people to use spack and deal with problems,,,keep up the good work
11/17/2020 20:46:32,Scientist/Researcher,University HPC/Computing Center,United States,Yes,"Traditional HPC / Simulation, Computer Science Research",Word of mouth,3,Packages,develop,"macOS, Red Hat, CentOS, Ubuntu, Debian, Fedora",10 - 100,"2.7, 3.8",Do it!,Do it!,spack load,"Module generation, build-env (debug a build)","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc, XL",Not Important,Critical,Not Important,Not Important,Very Important,Very Important,Critical,Critical,Very Important,Not Important,Somewhat important,Not Important,,Maybe,Yes,"Documentation, Slack, Mailing List, Coworkers",Yearly,No,OK,OK,OK,Good,,,,,,
11/17/2020 20:47:08,Scientist/Researcher,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,"Traditional HPC / Simulation, AI/ML, Computer Science Research",Word of mouth,3,Packages,0.15,"Red Hat, Ubuntu, Debian, Arch",10 - 100,3.8,Do it!,Do it!,"spack load, Spack environments","Environments, Module generation","AMD, Intel, IBM Power, ARM","NVIDIA, Intel","gcc, Intel OneAPI / dpc++, NVIDIA Compilers (new PGI), LLVM, nvcc",Very Important,Critical,Critical,Slightly Important,Very Important,Critical,Somewhat important,Slightly Important,Somewhat important,Not Important,Not Important,Not Important,Better re-use of pre-installed system libraries,No,No,"Documentation, Coworkers",Yearly,Probably not,OK,Good,OK,Good,,,Long build time,Reuse of preinstalled system libraries when possible,,
11/17/2020 22:11:21,User Support Staff,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,"Traditional HPC / Simulation, High Energy Physics",Word of mouth,5,"Packages, Core Features, Mailing List, Issues","0.12, 0.15, develop","Red Hat, CentOS, Arch, Amazon Linux, SuSE, Alpine","> 1,000","2.7, 3.7, 3.8",Do it!,I'd live (I can provide Python 3 somehow),"Spack environments, Lmod, Environment Modules (TCL modules)","Environments, Module generation, Chaining, Stacks (matrices in environments), Binary Caches, build-env (debug a build), spack-python (Python scripting), Command Extensions, Externals in packages.yaml, Concretization preferences in packages.yaml, spack ci (generate GitLab Pipelines)","AMD, Intel, IBM Power","NVIDIA, AMD","gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc, XL, CCE (Cray Compilers)",Critical,Very Important,Very Important,Not Important,Slightly Important,Somewhat important,Slightly Important,Somewhat important,Somewhat important,Somewhat important,Very Important,Not Important,ASP concretizer,"Yes, I'd attend",Yes,"Documentation, Source Code",Weekly,Probably not,Good,Excellent,OK,Excellent,We use spack to install most facility-provided software on OLCF HPC machines. We have a single bot user that installs a cultivated list of specs (transitioning to spack environments) following curated package preferences for each of our machines under a CI process.,"The ability to define - in a single set of compact configuration files that can be kept in version control - a clear and repeatable set of package builds with sane HPC defaults and configuration options across a sufficiently wide range of build systems, compilers, and architectures using a consistent interface.","Changes to preferred package versions/options in an environment don't get applied to spec matrices without `spack concretize -f`; It could be useful though not critical, if spack could detect changes to environment-scope package preferences and re-concretize existing specs when non-trivial changes occur.

A full environment reconcretization also (at least in v0.15.0) adds a new blank line above block comments in `spack.yaml`. It would be nice if spack (by default) did not write back to `spack.yaml` and only `spack.lock` during environment concretization with an option to write back to `spack.yaml` only occasionally (eg, before `spack.yaml` is committed to a git repo) at the user's discretion to fill out missing schema fields.

It would be useful during initial provisioning to have an option on `spack install` for environments that is opposite to `--fail-fast`. Best effort will continue the build as far as it can for the current root spec/parent specs but it would be useful to pass an explicit option at the command line to allow spack to continue trying to install the rest of the environment specs rather than comment-out problem specs from an environment and fully re-concretize.

If there was at all a way to have `--pdb` drop into an ipython/jupyter shell (if available), that would be awesome. Not sure it's possible. I looked into it a little with Greg once at a hackathon and it seemed potentially possible but not critical enough to follow up on it.",CrayPE integration via json file; ASP concretizer to allow mixed-toolchain builds where duplicate dependency packages can be built with each toolchain separately where DAG nodes are either 1) not link-dependencies (usable under all compilers; e.g. build buildtime deps with GCC and application deps with PGI allowing both sub-trees in the DAG to build the same common yet isolated package) and/or 2) where the compilers are known to produce link-compatible libraries (e.g. always use GCC to build boost even if it will be linked into an application built with another compiler that is C/C++ ABI compatible such as PGI supporting the same C++ standard).,"None that we haven't been able to rapidly write for ourselves. We do tend to modify upstream packages to work around quirks in our machines and configuration preferences (notably packages like openmpi to better handle our specific scheduler, IO, and fabric preferences). However, it is often the case that our modifications are not generic or universally safe enough to feel compelled to push them upstream. I know I've been saying for years that we want to be better in this regard but our production workflow has been, historically, not conducive for making our changes easily contributable. After we've fully migrated our production deployment framework to use spack environments, the new scheme will be better suited for pushing our improvements up without adding onerous overhead to our daily workloads.","Todd, Greg, Adam Stewart, Massimiliano, and all the rest are doing a great job. Many thanks to you all and the greater spack community for making the installation and maintenance of deeply combinatoric multi-arch/mulit-toolchain software immeasurably less painful."
11/17/2020 21:54:55,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,"Traditional HPC / Simulation, Computer Science Research, Embedded Systems",Used at my site,3,"Packages, Slack Discussions, Issues",develop,"macOS, Red Hat, Ubuntu, Arch, SuSE, TOSS",100 - 200,"3.6, 3.7, 3.8",Do it!,Do it!,"spack load, Spack environments, Lmod, Environment Modules (TCL modules)","Environments, Module generation, build-env (debug a build), Python extensions (link python packages into interpreter prefix), Externals in packages.yaml, Concretization preferences in packages.yaml, Distributed Builds (srun spack install), spack dev-build","AMD, Intel, IBM Power, ARM","NVIDIA, AMD","gcc, LLVM, AMD aocc, AMD hipclang, XL, CCE (Cray Compilers)",Very Important,Critical,Somewhat important,Slightly Important,Slightly Important,Somewhat important,Very Important,Somewhat important,Very Important,Slightly Important,Slightly Important,Not Important,Better concretizer that maximizes already installed package re-use,"Yes, I'd attend",Yes,"Documentation, Slack, Coworkers",Weekly,Probably,Excellent,Excellent,Excellent,Good,"1) Create a spack env with all the packages necessary to do my research experiments. Distribute the spack.yaml and lock files along with my research artifacts for better reproducibility.
2) Log on to a new system, clone spack, install my ""daily driver"" tools/toolchains (e.g., recent versions of python, git, tmux, htop, emacs)
3) User files a bug that our software package breaks with a given combination of dependencies/compilers.  Log on to a system and reproduce with Spack, then fix the bug in our software.","I'm still in dependency hell, but Spack took me from the 7th circle (violence - for the violence I'd like to commit against my keyboard while building things) to the 3rd circle (gluttony - for the voracious appetite I now have for spack-installed packages and the indulgent number of dependencies they require).",,New concretizer that makes better use of already installed packages,,
11/17/2020 22:06:15,Scientist/Researcher,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,Traditional HPC / Simulation,Presentation,2,Packages,develop,"Ubuntu, Fedora",1 - 10,3.8,Do it!,Do it!,,Externals in packages.yaml,"AMD, Intel, IBM Power","NVIDIA, AMD","gcc, Intel Compilers, Intel OneAPI / dpc++, AMD hipclang, nvcc",Not Important,Very Important,Not Important,Not Important,Not Important,Not Important,Very Important,Very Important,Very Important,Not Important,Not Important,Very Important,,Maybe,No,Documentation,Yearly,No,Good,OK,OK,OK,Provide spack installer for library I develop,,,,,
11/17/2020 20:50:46,Software Developer,University HPC/Computing Center,United States,Yes,Traditional HPC / Simulation,Used at my site,2,"Packages, Slack Discussions, Issues",develop,"Red Hat, CentOS, Ubuntu, Debian, SuSE, Fedora",10 - 100,"2.7, 3.5",Do it!,I'd live (I can provide Python 3 somehow),"Lmod, Environment Modules (TCL modules)","Module generation, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel OneAPI / dpc++, nvcc",Very Important,Somewhat important,Very Important,Slightly Important,Somewhat important,Somewhat important,Very Important,Somewhat important,Somewhat important,Somewhat important,Very Important,Not Important,"Some form of integrated pre-build config testing, like what autotools does.   For example, before 'spack spec/install', I run a script that scans the system and makes version/variant choices for me.","Yes, I'd attend",Yes,"Documentation, Slack",Monthly,Probably not,Excellent,Excellent,Good,Good,I use spack to build my project's prereqs/dependencies and then use autotools to work on my project.,"the community, which is excellent","You claim that spack is ""easy to use"", but IMHO spack is an advanced system for advanced users and some things are complicated.  It's a hard problem.",the new concretizer,,"I would like to see a separate, low-volume announcement either mailing list, or slack channel, or web page, or something with heads up for major changes in spack.  For example, the format of config.yaml for install_tree changed last week and this broke one of may daily scripts.   Now, I figured it out, but 'heads up' would have been nice.  But this should be low-volume, not every new package."
11/17/2020 20:51:49,User Support Staff,Company,United States,No,"Traditional HPC / Simulation, AI/ML",Presentation,2,"Packages, Slack Discussions, Issues",develop,"Red Hat, CentOS",100 - 200,"3.6, 3.7, 3.8",Do it!,Do it!,"Lmod, Environment Modules (TCL modules)","Environments, Module generation, spack containerize, build-env (debug a build), Externals in packages.yaml, Concretization preferences in packages.yaml",Intel,NVIDIA,"gcc, Intel Compilers",Critical,Critical,Critical,Somewhat important,Critical,Somewhat important,Slightly Important,Slightly Important,Slightly Important,Not Important,Somewhat important,Not Important,"I suppose if I'm being greedy 'spack containerize' could be a little friendlier by taking options to tune the generated recipe on the fly.  E.g.,  spack containerize --dist=centos7 --singularity --package-list=""gcc@9.2,openmpi@4,python@3.8"" > Singularity.

Pie in the sky wish... Spack channels, akin to Conda channels, become a thing and is taken up by developers of closed source scientific applications commonly used on HPC clusters.  'spack install X' securely fetches the closed source vendor distribution and brings installation under spack.  Examples might include software from Ansys, Biovia, Schrodinger, Openeye, or Siemens.",Maybe,Yes,"Documentation, Slack, GitHub",Monthly,Probably,Excellent,Excellent,Good,Excellent,We (a user-support staff of 2) use spack to deliver the production versions of whatever it can build easily to r&d clusters at a large pharma company.  Spack-installed software makes up about 25% of the total set of end-user modules on our clusters.  ,"Spack provides the foundation of the software stack on our cluster: reproducible, easy installations of the basic toolchain -- GCC, OpenMPI, Cuda, Bash, git, cmake, etc. and some scientific applications that are open source and readily compiled with that tool chain.  In this role it (a) saves time for support staff and (b) improves the quality of our software stack by facilitating delivery of more robust, more timely, and more up to date versions of these tools that would otherwise be provided over the cluster lifecycle.","I don't know how to safely update a spack installation in place (git pull) without triggering rehashing and a massive number of rebuilds within that stack.  This makes updating spack tricky on production systems that rely on the same software installations working day after day, year after year.

Building anything with an intel tool chain.

Most of our scientific apps that are compiled with an Intel toolchain, or are Python libraries, or come from 3rd party vendors, are managed outside of Spack.
",T. Gamblin has given presentations on future improvements to the concertizer that look exciting.  Anything that improves or builds on container support is also very welcome.  'spack containerize' could take a few options and be a bit friendlier. ,I thought of a few but then ran 'spack list' and they have been added since the last time I checked.  The package list is quite good.,Spack is extraordinary and blows away all past attempts to bring sanity to HPC software.  I encourage you to offer commercial support. Please have support tiers that allow us to select an appropriate level of support.
11/17/2020 20:52:36,User Support Staff,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,No,Traditional HPC / Simulation,Word of mouth,3,"Packages, Slack Discussions, Issues",develop,"Red Hat, SuSE, Cray","> 1,000",3.6,Do it!,Do it!,"Lmod, Environment Modules (TCL modules)","Environments, Module generation, spack containerize, Stacks (matrices in environments), build-env (debug a build), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, ARM",NVIDIA,"gcc, Intel Compilers, LLVM, AMD aocc, nvcc, CCE (Cray Compilers), armclang",Very Important,Somewhat important,Somewhat important,Not Important,Slightly Important,Slightly Important,Not Important,Slightly Important,Slightly Important,Slightly Important,Slightly Important,Not Important,Charliecloud integration,Maybe,Yes,"Documentation, Slack",Weekly,Probably,Good,Good,Good,Good,,,Managing stacks for several types of machines.,"New concretizer reducing the rebuild of dependencies across multiple compilers that don't need to be built with any particular compiler.  Allow for more layers of machine differentiation (specifically, interconnect).",,
11/17/2020 20:53:30,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,"Traditional HPC / Simulation, Compiler Testing",Word of mouth,5,"Packages, Issues",0.15,Red Hat,"> 1,000",2.7,Unacceptable  (it's the only python on important machines),Unacceptable,"Lmod, Environment Modules (TCL modules)","Environments, build-env (debug a build), Externals in packages.yaml, Concretization preferences in packages.yaml, Distributed Builds (srun spack install)","AMD, Intel, IBM Power, ARM","NVIDIA, AMD","gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, AMD hipclang, nvcc, XL, CCE (Cray Compilers), armclang",Somewhat important,Very Important,Very Important,Not Important,Slightly Important,Very Important,Somewhat important,Very Important,Very Important,Not Important,Very Important,Not Important,Moving the install location after builds,"Yes, I'd attend",Yes,Coworkers,Yearly,"Yes, definitely!",Good,Good,Good,Good,,building my 100+ project libs,,,,
11/17/2020 21:55:47,Scientist/Researcher,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,No,"Traditional HPC / Simulation, High Energy Physics",Presentation,4,"Packages, Issues","0.14, 0.15","macOS, TOSS, Red Hat",1 - 10,2.7,Do it!,I'd live (I can provide Python 3 somehow),spack view,"Environments, Stacks (matrices in environments), Python extensions (link python packages into interpreter prefix), Externals in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD","gcc, Intel Compilers, nvcc, XL, CCE (Cray Compilers), armclang",Somewhat important,Very Important,Very Important,Not Important,Very Important,Somewhat important,Very Important,Very Important,Somewhat important,Not Important,Critical,Not Important,"Better debug info for offending file, e.g. bug in packages.yaml syntax",Maybe,No,"Slack, Mailing List",Weekly,No,OK,Excellent,Good,Good,Third party library compile for ICF simulation code and workflow tool.,Defining a new compiler and having spack create all of the libraries is a joy.,Upgrading to a new version when spack arch changes,"I would like a system where I give a list of libraries, including multiple versions of a single library, and it would concretize together and be available in a single collection with no other libraries with the same compiler/arch in the list.",,
11/17/2020 20:55:11,Scientist/Researcher,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,"Traditional HPC / Simulation, Computer Science Research",Word of mouth,4,Packages,0.14,Ubuntu,1 - 10,3.7,Do it!,Do it!,"spack load, Spack environments, Environment Modules (TCL modules)","Environments, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, LLVM, AMD hipclang, nvcc",Somewhat important,Very Important,Somewhat important,Not Important,Somewhat important,Very Important,Very Important,Slightly Important,Somewhat important,Not Important,Slightly Important,Not Important,,Maybe,No,Documentation,Monthly,No,Excellent,Good,OK,Good,,,,,,
11/17/2020 20:55:59,Scientist/Researcher,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,"Traditional HPC / Simulation, Computer Science Research",Word of mouth,3,Packages,develop,"Red Hat, CentOS, Ubuntu, Debian",100 - 200,"2.7, 3.5",Do it!,Unacceptable,"spack load, Lmod, Environment Modules (TCL modules)","Environments, Module generation","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, nvcc, XL",Somewhat important,Very Important,Slightly Important,Somewhat important,Critical,Critical,Critical,Critical,Slightly Important,Slightly Important,Critical,Critical,,"Yes, I'd attend",No,Documentation,Monthly,Probably,Good,Good,Good,Good,,,,,,
11/17/2020 20:56:46,Software Developer,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,"Traditional HPC / Simulation, Computer Science Research",Presentation,3,"Packages, Core Features, Slack Discussions, Mailing List, Issues","0.15, develop","CentOS, Ubuntu","500-1,000","3.6, 3.7, 3.8",Do it!,Do it!,spack load,"Environments, spack external find, Externals in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers",Not Important,Somewhat important,Not Important,Not Important,Not Important,Not Important,Somewhat important,Somewhat important,Not Important,Not Important,Somewhat important,Not Important,I really really wish the package repository and core spack code were not in the same repo.  On multiple occasions I have wanted to update one and had something break in the other on HPC platforms with fragile development environments.,No,No,"Documentation, Slack, Mailing List",Monthly,No,Good,Good,OK,Good,I help to maintain a project (Mochi) that deliberately has a number of small subpackages (the point of the project is composability).  I rely on spack to correctly assemble combinations of these packages for different use cases.  It's invaluable in this context.,ability to handle complex dependency chains,"close coupling between spack (the core code) and the package repositories, lack of regression testing for key DOE HPC platforms, unexpected command line changes",,,
11/17/2020 20:57:30,Software Developer,Company,United States,No,Traditional HPC / Simulation,Used at my site,1,Issues,"0.15, develop","Red Hat, CentOS, Ubuntu, Debian, SuSE, Fedora",10 - 100,"2.7, 3.7",Do it!,Do it!,"Spack environments, Lmod","Environments, Module generation, build-env (debug a build)","AMD, Intel","NVIDIA, AMD","LLVM, AMD hipclang, nvcc, CCE (Cray Compilers)",Slightly Important,Somewhat important,Somewhat important,Slightly Important,Somewhat important,Very Important,Somewhat important,Slightly Important,Slightly Important,Slightly Important,Critical,Slightly Important,,Maybe,Yes,"Documentation, Coworkers",Monthly,Probably not,OK,OK,Bad,OK,Building third party prereqs quickly before building optimized large codes,Set it up once and use be able to do with ,Mixed sets of compiler flags for various portions of builds,Adding capabilities for various compiler flags for different portions of builds,,
11/17/2020 20:58:06,Scientist/Researcher,University HPC/Computing Center,United States,Yes,"Traditional HPC / Simulation, Computer Science Research",Word of mouth,3,No,"0.12, 0.14",CentOS,200 - 500,2.7,Do it!,Unacceptable,"spack load, Spack environments",Chaining,"AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, LLVM, AMD aocc, AMD hipclang, XL, armclang",Somewhat important,Very Important,Very Important,Slightly Important,Slightly Important,Very Important,Very Important,Critical,Very Important,Very Important,Somewhat important,Not Important,,"Yes, I'd attend",No,"Documentation, Coworkers",Daily,No,OK,Good,Bad,Good,research on Space-based tools; traditional debugging,automatic building of prerequisites,access to build error messages artifacts,more packages that work,,
11/17/2020 20:58:45,System Administrator,University HPC/Computing Center,United States,No,"Traditional HPC / Simulation, Bioinformatics",Word of mouth,2,Packages,develop,CentOS,10 - 100,"2.7, 3.6, 3.8",Do it!,Do it!,Lmod,"Environments, Module generation, spack containerize, Chaining, build-env (debug a build)","AMD, Intel",NVIDIA,gcc,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,Not Important,tensorflow working on centos/rhel,"Yes, I'd attend",Yes,Documentation,Weekly,Probably not,Good,Excellent,Good,Good,"user requests help with package a, check to see if package a is in the spack repo, if  yes, rejoice! If the package isn't there I try to manually build it and then transfer that into a spack package. This is hard, but probably because building software from source with all these weird dependencies is hard? ","when it works, it is really great. ",Tensorflow not quite working on centos/rhel,"There appears to be some amount of unwritten package compatibility for centos/rhel and ubuntu/mac getting more focus. Are other HPC clusters running ubuntu, I thought it was centos/rhel mostly...",tensorflow rhel/centos,
11/17/2020 22:13:28,All of the Above,Other Public Research Lab,Germany,No,High Energy Physics,Used at my site,1,"Packages, Core Features, Slack Discussions, Issues","0.15, develop","macOS, CentOS, Ubuntu, Debian, SuSE, Fedora",200 - 500,"2.7, 3.6, 3.7, 3.8",Do it!,I'd live (I can provide Python 3 somehow),"spack load, Spack environments, spack view","Environments, Chaining, Stacks (matrices in environments), spack-python (Python scripting), Command Extensions, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, ARM",AMD,"gcc, LLVM",Critical,Slightly Important,Not Important,Not Important,Not Important,Not Important,Slightly Important,Not Important,Not Important,Not Important,Not Important,Not Important,Split the package definitions from spack core.,"Yes, I'd attend",Yes,"Documentation, Slack, Coworkers, Source Code",Weekly,Probably,Good,Good,OK,Good,Installing a big list of software for our HPC super computer. Maintaining the package recipes for this. Maintaining the CI.,"Most of the time, it just works.","* Top on the list: The concretizer. It even runs endlessly in some cases, and analyzing that isn't fun. It's really fragile.
* Automatic setting of LD_LIBRARY_PATH breaking too much, see #3955
Everything else is acceptable. Some things aren't fun, but we can handle them.","Despite fixing the concretizer:
Consider onboarding some people to review the package PRs.",,
11/17/2020 22:14:35,Software Developer,Other Public Research Lab,Germany,No,High Energy Physics,Technical Paper,1,"Packages, Issues","0.15, develop","macOS, CentOS, Ubuntu, Debian, SuSE, Fedora","> 1,000","2.7, 3.7, 3.8",Do it!,Do it!,"spack load, Spack environments, spack view","Environments, Module generation, Chaining, Stacks (matrices in environments), Binary Caches, spack-python (Python scripting), Command Extensions, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, ARM","NVIDIA, AMD","gcc, Intel Compilers, LLVM",Critical,Slightly Important,Slightly Important,Slightly Important,Somewhat important,Critical,Very Important,Very Important,Somewhat important,Not Important,Very Important,Not Important,"smarter concretizer, multi-package development mode","Yes, I'd present something!",No,"Documentation, Coworkers, Source Code",Daily,Probably not,Good,Good,OK,Good,"We want to deliver reproducible software distributions with pinned and thouroughly tested specs (versions, variants). We want to support multiple compilers/platforms.","flexibility, user-space package management","concretizer not finding obvious solutions, environments not composable",smarter concretizer,,
11/17/2020 21:01:30,Software Developer,Other Public Research Lab,Germany,No,"Traditional HPC / Simulation, Statistics / Data Analysis, High Energy Physics",Presentation,1,No,"0.12, 0.13, 0.14, 0.15","macOS, CentOS, Debian",10 - 100,"3.7, 3.8",Do it!,Do it!,"spack load, Spack environments, spack view","Environments, spack containerize, Chaining, Command Extensions, Externals in packages.yaml","AMD, Intel","NVIDIA, AMD","gcc, Intel Compilers, LLVM",Critical,Critical,Very Important,Not Important,Not Important,Critical,Somewhat important,Somewhat important,Somewhat important,Not Important,Critical,Not Important,,Maybe,Yes,"Documentation, Mailing List, Coworkers",Daily,No,OK,OK,Bad,Bad,Multiple package distribution for HEP experiments,,"concretiser, development packages (dev-build), system packages","concretiser, development packages (dev-build), system packages",,
11/17/2020 21:02:16,Software Developer,Other Public Research Lab,Germany,No,"Traditional HPC / Simulation, Statistics / Data Analysis, High Energy Physics",Word of mouth,1,No,"0.13, 0.15","macOS, CentOS, Debian",100 - 200,"2.7, 3.7",Do it!,Do it!,"spack load, Spack environments, spack view","Environments, Chaining, Externals in packages.yaml","AMD, Intel","NVIDIA, AMD","gcc, Intel Compilers, LLVM",Critical,Critical,Somewhat important,Not Important,Very Important,Critical,Somewhat important,Somewhat important,Very Important,Not Important,Very Important,Not Important,,"Yes, I'd attend",Yes,"Documentation, Coworkers",Weekly,No,Good,Good,OK,OK,Software stack installation on HPC system. Installation of software for HEP.,"Resolving dependencies, multi-version multi-configuration installations, builds for different targets","External packages, multi-package dev-build, concretizer",,,
11/17/2020 21:02:52,System Administrator,University HPC/Computing Center,United States,No,"Traditional HPC / Simulation, Computer Science Research",Tutorial,1,No,0.15,"macOS, CentOS, Ubuntu",10 - 100,3.6,Do it!,Do it!,"spack load, Lmod","Environments, Module generation, Chaining, Binary Caches, build-env (debug a build), spack external find, Concretization preferences in packages.yaml, Distributed Builds (srun spack install)","AMD, Intel, ARM",NVIDIA,"gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc",Very Important,Very Important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Slightly Important,Somewhat important,Not Important,shared install support for HPC,"Yes, I'd attend",Yes,"Documentation, Slack",Weekly,Probably not,Excellent,Good,Excellent,Excellent,Deploying complex software stack in heterogenous (Intel + AMD) HPC system and supporting users who can't do 'configure; make; make install' but want custom everything.,"Build dependency resolution via concretization and DAG for complex arch, compiler, mpi matrix and automatic generation of Lmod module files.",Providing a shared binary / configuration for beginning HPC users. Power users can be trusted to do the right thing. Not so much beginners.,"Add support for shared install for HPC system, common binary, common config, etc for non-developer users.","AMD Optimizing C/C++ Compiler and related libraries (some exist, not aocc).",Awesome work... keep it up!
11/17/2020 21:03:28,Manager,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,Computer Science Research,Tutorial,4,Packages,develop,"macOS, Red Hat, CentOS, Ubuntu, SuSE, Fedora","500-1,000","3.5, 3.6, 3.7, 3.8",Do it!,Do it!,spack load,"build-env (debug a build), Externals in packages.yaml","Intel, ARM",Intel,"gcc, Intel Compilers, XL",Critical,Very Important,Very Important,Not Important,Not Important,Somewhat important,Not Important,Not Important,Not Important,Not Important,Somewhat important,Not Important,Improve error messages,"Yes, I'd attend",Yes,Slack,Never,Probably not,Bad,Good,Good,Good,,,,,,
11/17/2020 21:03:58,Scientist/Researcher,Other Public Research Lab,United States,No,"Traditional HPC / Simulation, Statistics / Data Analysis, AI/ML, Computer Science Research, Bioinformatics",Word of mouth,0,"Packages, Issues",0.15,"CentOS, Ubuntu",100 - 200,3.8,Do it!,Do it!,Spack environments,Environments,Intel,NVIDIA,"gcc, LLVM, nvcc",Critical,Critical,Critical,Not Important,Somewhat important,Critical,Critical,Critical,Critical,Not Important,Critical,Slightly Important,Include packages of compiler toolchain ,Maybe,Yes,"Documentation, Slack",Monthly,No,Good,Excellent,Good,Excellent,Use spack environment to install and use software,package management ,It's very slow on NFS,Improve its computational performance on network file system,,
11/17/2020 21:04:40,Scientist/Researcher,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,"Traditional HPC / Simulation, AI/ML, Computer Science Research, High Energy Physics",Word of mouth,3,"Core Features, Slack Discussions, Issues",0.14,"macOS, Red Hat",200 - 500,"3.6, 3.7, 3.8",Do it!,Do it!,"Lmod, Environment Modules (TCL modules)","Environments, Module generation, Chaining","Intel, ARM",NVIDIA,"gcc, Intel Compilers, NVIDIA Compilers (new PGI), LLVM, nvcc, CCE (Cray Compilers), armclang",Somewhat important,Slightly Important,Slightly Important,Not Important,Not Important,Critical,Somewhat important,Slightly Important,Slightly Important,Not Important,Slightly Important,Very Important,,"Yes, I'd present something!",Yes,"Documentation, Slack",Weekly,Probably not,Excellent,Excellent,Excellent,Excellent,We embed Spack in our finite element code’s devops toolset and use it extensively for dependency management.  Dozens of developers and our CI system run it under the hood.,Documentation and slack.,Use configuration scope being hard coded to ~/.spack.  We build on many machines all with a common home directory.  Having Spack look in and populate ~/.spack is a show stopper for us adopting mainline Spack and not our own fork.  Configuration scopes and environments have not been sufficient since we have to assure the user’s environment has no impact on our builds.,A better `spack setup`,,
11/17/2020 21:05:19,Scientist/Researcher,Other Public Research Lab,Spain,No,Traditional HPC / Simulation,Word of mouth,1,Slack Discussions,0.15,"Ubuntu, Arch, Fedora, Alpine",10 - 100,"3.7, 3.8",Do it!,Do it!,"Spack environments, Lmod","Environments, Module generation, build-env (debug a build)",Intel,NVIDIA,"gcc, Intel Compilers, NVIDIA Compilers (new PGI), CCE (Cray Compilers)",Not Important,Slightly Important,Not Important,Not Important,Not Important,Not Important,Somewhat important,Not Important,Slightly Important,Not Important,Somewhat important,Not Important,,Maybe,No,"Documentation, Slack",Monthly,Probably not,Good,Excellent,Good,Good,,"Easy and reproducible way to install many versions (different compilers, flags, etc.) of our required libraries.",,,,Spack rocks! :-)
11/17/2020 21:05:50,System Administrator,University HPC/Computing Center,United States,No,"Traditional HPC / Simulation, AI/ML",Used at my site,1,No,0.15,CentOS,10 - 100,3.7,I'd live.  (I can provide 2.7 somehow),Do it!,Environment Modules (TCL modules),"Environments, Module generation, spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), nvcc",Somewhat important,Somewhat important,Somewhat important,Slightly Important,Slightly Important,Not Important,Somewhat important,Not Important,Very Important,Not Important,Somewhat important,Not Important,,Maybe,No,"Documentation, Slack, Mailing List, Coworkers",Monthly,Probably,Good,Good,OK,Good,,,,,,
11/17/2020 21:06:30,Software Developer,Other Public Research Lab,United States,Yes,Computer Science Research,Used at my site,3,"Packages, Slack Discussions, Issues",develop,"Red Hat, CentOS, Ubuntu, Windows Subsystem for Linux (WSL)",100 - 200,"2.7, 3.8",Do it!,Do it!,"spack load, Spack environments","Environments, Stacks (matrices in environments), Binary Caches, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD","gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, nvcc, CCE (Cray Compilers)",Critical,Very Important,Very Important,Somewhat important,Very Important,Very Important,Very Important,Somewhat important,Somewhat important,Critical,Somewhat important,Slightly Important,,Maybe,Yes,"Documentation, Slack",Monthly,Probably not,Good,Excellent,Good,Excellent,,I can install software quickly and repeatably without worrying about dependencies.,,,,I should be using more of Spack's features from that list.
11/17/2020 22:05:42,Scientist/Researcher,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,"High Energy Physics, Visualization",Used at my site,3,Packages,0.14,"macOS, Red Hat, Ubuntu",100 - 200,"2.7, 3.7",I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),Custom script or env vars,Concretization preferences in packages.yaml,"AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), nvcc, XL, CCE (Cray Compilers)",Very Important,Slightly Important,Somewhat important,Slightly Important,Somewhat important,Very Important,Very Important,Somewhat important,Slightly Important,Not Important,Very Important,Not Important,,"Yes, I'd attend",Yes,"Documentation, Slack",Monthly,No,OK,OK,OK,OK,building dependencies,,inter dependencies with many variants makes a huge/complicated package file,,,
11/17/2020 21:08:04,Scientist/Researcher,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,No,Traditional HPC / Simulation,Presentation,3,"Packages, Core Features, Slack Discussions, Mailing List, Issues","0.15, develop","Red Hat, CentOS, Ubuntu, Windows Subsystem for Linux (WSL), Cray","> 1,000","3.7, 3.8",Do it!,Do it!,"Spack environments, Environment Modules (TCL modules)","Environments, Module generation, spack containerize, spack-python (Python scripting), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, NVIDIA Compilers (new PGI), LLVM, AMD hipclang",Very Important,Somewhat important,Somewhat important,Slightly Important,Slightly Important,Somewhat important,Slightly Important,Very Important,Critical,Very Important,Somewhat important,Not Important,Compilers as dependencies that get loaded when any package built with them is loaded (when autoload : true is set for TCL modules) and when an environment is loaded.,Maybe,No,"Documentation, Slack, Mailing List",Weekly,Probably not,Excellent,Excellent,Excellent,Excellent,,,,More rigorous CI testing and binary package mirrors to ease transition to spack for sysadmins at non DoE sites,,
11/17/2020 21:08:47,Software Developer,Company,United States,No,Bioinformatics,Word of mouth,4,"Packages, Documentation, Slack Discussions, Mailing List, Issues",develop,CentOS,"500-1,000","2.7, 3.7",Do it!,Do it!,Lmod,"Environments, Module generation, spack containerize, Chaining, build-env (debug a build), Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, LLVM",Critical,Not Important,Somewhat important,Slightly Important,Not Important,Not Important,Slightly Important,Slightly Important,Not Important,Not Important,Slightly Important,Not Important,,"Yes, I'd attend",Yes,"Documentation, Mailing List, GitHub",Daily,Probably not,Good,Excellent,Good,Good,Building tools for computational biology/bioinformatics and related support bits in industry.,"Easy extensibility, great community",,"concretizer, trim/clean features and catch up documentation",,"THANK YOU!   GPU questions insisted on a choice, should have had a ""none"" option."
11/17/2020 21:56:34,Scientist/Researcher,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,"Traditional HPC / Simulation, Computer Science Research, High Energy Physics",Word of mouth,2,"Packages, Slack Discussions, Issues",develop,"Red Hat, CentOS, SuSE, TOSS",10 - 100,"2.7, 3.7",Do it!,Do it!,"Spack environments, Environment Modules (TCL modules)","Environments, Module generation, spack containerize, Stacks (matrices in environments), build-env (debug a build), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM",AMD,"gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), AMD aocc, AMD hipclang, XL, CCE (Cray Compilers), Fujitsu Compilers",Critical,Somewhat important,Very Important,Not Important,Not Important,Somewhat important,Slightly Important,Slightly Important,Slightly Important,Not Important,Very Important,Not Important,Mixed toolchain hardening; multi-developers contributing to the same Spack *Environment*; Advanced containerization,"Yes, I'd attend",Yes,"Documentation, Slack, Coworkers, GitHub",Weekly,Probably not,Good,Good,Excellent,Good,Build our entire deep-dependency stack,Spack Environments,Can't use a single instance with multiple developers,Harden mixed toolchains; Make multiple-developers in Spack Environments bullet proof.,,I'd like to discuss advanced container building
11/17/2020 21:10:16,Scientist/Researcher,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,No,Traditional HPC / Simulation,Word of mouth,2,Issues,0.14,"CentOS, Ubuntu, Fedora, Windows Subsystem for Linux (WSL)",1 - 10,3.6,Do it!,Do it!,"spack load, Lmod","Environments, Module generation, spack-python (Python scripting), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power","NVIDIA, AMD, Intel","gcc, Intel Compilers, NVIDIA Compilers (new PGI), LLVM, nvcc",Somewhat important,Very Important,Somewhat important,Slightly Important,Slightly Important,Very Important,Somewhat important,Somewhat important,Somewhat important,Not Important,Somewhat important,Not Important,,Maybe,No,Coworkers,Never,Probably not,OK,OK,OK,OK,,"When it works, I can build software on systems that don't come preinstalled with my pre-depends.",sometimes I want to see internal details of a package that spack builds and spack makes that hard.,,,
11/17/2020 22:14:00,Software Developer,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,No,"High Energy Physics, Web applications",Presentation,1,"Packages, Core Features","0.13, 0.14, develop","macOS, Red Hat, CentOS, Ubuntu","500-1,000","2.7, 3.6, 3.8",Do it!,I'd live (I can provide Python 3 somehow),"spack load, Environment Modules (TCL modules), UPS","Environments, Module generation, Binary Caches, build-env (debug a build), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel","NVIDIA, AMD","gcc, Intel Compilers, LLVM",Critical,Very Important,Somewhat important,Somewhat important,Somewhat important,Very Important,Somewhat important,Somewhat important,Very Important,Somewhat important,Slightly Important,Slightly Important,Speed improvements/reduced CPU during builds,Maybe,Yes,"Documentation, Slack, Coworkers, Source Code",Weekly,Probably,OK,Excellent,Good,Good,"Well, we have lots ;-).  We're trying to replace our site-local ""ups"" package management system, which is used in local system package areas for application servers, shared experiment software areas distributed globally via CVMFS for interactive and distributed GRID/batch computing use, experiment remote package areas (i.e. at universites) , local package development of experiment software framework components using shared package areas for dependencies...",Effective support for multiple installed platforms and versions.,"Not good support for data-file/config-file packages which aren't compiled -- they are replicated per platform unnecessarily.
Difficult to specify wanting to use installed packages for dependencies, you have to iterate on ""spack spec --install-status"", ""spack find --long"" and issue a long spec with hashes...
Would be nice to have a shorthand for 'spack activate foo-`spack arch --operating-system`' for having matching environments per platform that people could activate with the same command line.",Forge ahead with the new concretizer!,Expanded Ruby support generally.,I think there are two major use cases for Spack -- 1) a package area for an optimized installs for a specific computing cluster; 2) a shared package area for a variety of systems with installs built for least-common-denominator; the current documentation doesn't cover 2 as well.
11/17/2020 21:11:55,Software Developer,Company,Germany,No,Computer Science Research,Birds-of-a-feather (BOF) at conference,1,No,0.14,SuSE,1 - 10,"3.7, 3.8",Do it!,Do it!,Lmod,"Module generation, spack external find, Externals in packages.yaml, Distributed Builds (srun spack install)","AMD, Intel, ARM","NVIDIA, AMD, Intel",gcc,Somewhat important,Critical,Critical,Slightly Important,Somewhat important,Somewhat important,Very Important,Somewhat important,Somewhat important,Somewhat important,Very Important,Not Important,external repositories,No,No,"Documentation, Coworkers",Weekly,No,Bad,Bad,OK,OK,,,,,,
11/17/2020 21:12:33,System Administrator,University HPC/Computing Center,Switzerland,No,"Traditional HPC / Simulation, Statistics / Data Analysis, Bioinformatics",Presentation,4,"Packages, Slack Discussions, Mailing List, Issues","0.14, 0.15",Red Hat,200 - 500,"3.6, 3.7",Do it!,Do it!,Lmod,"Environments, Module generation, spack containerize, Chaining, Stacks (matrices in environments), build-env (debug a build), Python extensions (link python packages into interpreter prefix), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, Intel Compilers, AMD aocc, nvcc",Very Important,Very Important,Very Important,Not Important,Not Important,Very Important,Slightly Important,Not Important,Not Important,Not Important,Somewhat important,Not Important,,"Yes, I'd attend",Yes,"Documentation, Slack",Daily,Probably,Excellent,Excellent,Good,Excellent,"Rather heterogeneous cluster with an environment per architecture. Currently having lots of fun packaging bioinformatics tools.

https://c4science.ch/source/dcsr-spack-site/
",Environments and spec matrices,Any update (git pull) brings in new package versions which can change the concretisation. ,The new concretiser + Separate the builtin package repository from the spack core. ,Probably new build system support like Julia / Golang,Keep up the good work!
11/17/2020 21:47:39,Scientist/Researcher,Company,United Kingdom,No,"Traditional HPC / Simulation, Computer Science Research",Used at my site,4,,0.15,"Red Hat, CentOS, Ubuntu, SuSE, Windows Subsystem for Linux (WSL)",200 - 500,"2.7, 3.6",I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),Environment Modules (TCL modules),"Module generation, Chaining, build-env (debug a build), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD","gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc, XL, CCE (Cray Compilers), armclang",Somewhat important,Very Important,Very Important,Somewhat important,Somewhat important,Very Important,Very Important,Very Important,Very Important,Somewhat important,Very Important,Somewhat important,,"Yes, I'd attend",Yes,"Documentation, Slack, Mailing List, Coworkers",Weekly,Probably,OK,Excellent,Excellent,Good,deploying software for users,deploying software,things break between versions,stop things breaking between versions,,
11/17/2020 21:14:33,Software Developer,Company,United States,No,Embedded Systems,Used at my site,0,"Slack Discussions, Issues",0.15,Ubuntu,100 - 200,3.7,Do it!,Do it!,Spack environments,"Environments, Binary Caches, build-env (debug a build)",Intel,NVIDIA,"gcc, LLVM",Not Important,Not Important,Very Important,Very Important,Not Important,Very Important,Slightly Important,Slightly Important,Not Important,Not Important,Slightly Important,Not Important,,"Yes, I'd attend",No,"Documentation, Slack, Coworkers",Weekly,Probably,OK,Good,Good,Good,"We have spack running both natively in ubuntu and in an ubuntu docker image with an environment, our own supplementary package repo, and our own binary cache. We use spack to install our package under development and all of its dependencies (both build and runtime). We activate the environment as our primary development environment. This means we want to use the compilers, the build systems, all of the build dependencies, etc. We support developers running this environment either natively or through docker + mounted file system. Anytime we update our package repo or upgrade/add a dependency, we generate a new docker image and ask that all of our developers install the latest spack environment.",Uniform environment with build dependencies consistent for all of our developers.,Dealing with missing compilers / caching of missing compiler packages.,"Parallelize operations like cache uploads and downloads, etc. We do a lot of installs because we are setting up and tearing down environments for development, and speeding this up even more would be great!",,We use spack primarily as a development environment package manager. Would like to see the continued evolution of Spack for this purpose.
11/17/2020 21:15:27,Software Developer,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,Traditional HPC / Simulation,Word of mouth,3,"Packages, Core Features, Slack Discussions, Mailing List",develop,"Red Hat, Ubuntu","> 1,000",2.7,Do it!,I'd live (I can provide Python 3 somehow),spack load,"Module generation, Chaining, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), LLVM, nvcc, CCE (Cray Compilers)",Critical,Critical,Critical,Slightly Important,Not Important,Very Important,Critical,Very Important,Critical,Slightly Important,Very Important,Not Important,,Maybe,Yes,"Documentation, Slack",Daily,Probably,Excellent,Good,OK,Good,Most develop Spack packages on a Linux box.,Building unwieldy complex packages such as LLVM,Building boost,Support for OpenMP target offload for new compilers,new oneAPI Intel compilers,
11/17/2020 21:15:59,User Support Staff,University HPC/Computing Center,United States,No,Traditional HPC / Simulation,Word of mouth,0,No,0.15,CentOS,1 - 10,2.7,I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),Lmod,"Environments, Module generation, Stacks (matrices in environments), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel","NVIDIA, AMD","gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc",Somewhat important,Very Important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Very Important,Somewhat important,Very Important,Slightly Important,Somewhat important,Slightly Important,More robust CPU multi-target support. We are just evaluating Spack for that and the current chosen approach with definition matrices is more complicated than it has to be.,"Yes, I'd attend",Yes,"Documentation, Mailing List, Coworkers",Weekly,Probably not,Excellent,Good,Excellent,Excellent,"We are still in a planning stage to use Spack to install software on our Linux clusters, which have about 5 CPU generations/types. We plug in some existing packages, like the compilers, Matlab, etc, but hope to install new version of these with Spack in the future as well",Definitely saving the time of manually installing the programs.,,"I think the multi-target support would be nice, as we'll be building separate stacks for at least 3 different CPU generations, plus possibly the new AMDs, so, having a good way to do this plus plug into Lmod (= so that Lmod picks up the right target branch) would be great.",,"We'll need to get into routine use of Spack before we can provide more comments, but, I am sure we'll have some when we become regular users."
11/17/2020 21:16:32,System Administrator,University HPC/Computing Center,United States,No,"Traditional HPC / Simulation, Statistics / Data Analysis, Bioinformatics, High Energy Physics",Word of mouth,0,No,0.15,Red Hat,1 - 10,"2.7, 3.6",I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),Lmod,"Module generation, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, Intel Compilers, PGI",Somewhat important,Very Important,Somewhat important,Slightly Important,Somewhat important,Critical,Very Important,Somewhat important,Very Important,Not Important,Slightly Important,Not Important,Spack error messaging is terrible and most times is completely missing or not helpful.  I would benefit from some major attention.,Maybe,Yes,"Documentation, Mailing List",Daily,"Yes, definitely!",OK,Bad,OK,OK,"Our use case is to replace our RPM-based software stack install on every node (thousands) with a single install on a network share.  Spack helps with handling the dependencies and allowing us to create multiple installations of an app using different versions and different compilers and different versions of compilers, etc...  That's very important to us.",How Spack handles installation of multiple versions of the same app.  How Spack should be Linux OS agnostic (yet to be tested) so we can experiment with offering other Distros for users.,"Getting answers to questions when they come up.  The response on the Google groups is intermittent and hit or miss.  The Spack API is a not-helpful document.  Instead, to try to learn anything, I have to crawl through the python code.  Can I easily get the staging directory created for the package.py I'm writing??  Probably, but I can't tell.  How am I even supposed to know what information ""self"" or ""spec"" has in it?  The only way I find out right now is by grepping through the builtin/packages directory to see what other people did.","When an error happens in Spack, the error message is quite often not helpful.  There does not appear to be a lot of exception catching in the code.  Sometimes it just says ""Error: "" and then what appears to be a part of a hash.  Even the verbose error messages (such as an irreconcilable version constraint) do not give enough information to know what the problem is.",,"A good percentage of our applications are installed as pre-built binaries.  It is therefor annoying that they end up ""under"" gcc, both as an install directory and as a module file.  I can't even install a package until a compiler is specified, even if that package doesn't require a compiler.  For example, I tried creating an environment and putting the intel parallel studio in the spack.yaml file, but that caused errors because a compiler hadn't been found yet.  Well duh...that's why I'm trying to install one....
The ""resources"" capability in Spack is completely under-documented and wildly inconsistent.  I still do not know the difference between ""destination"" and ""placement"" when creating a resource, I have to do trial and error to get it to put the expanded resources in the right place.  Also hidden and maddening is the completely different behavior of Spack solely dependent on if an archive expands into a separate directory or not."
10/6/2020 13:22:48,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,Computer Science Research,Used at my site,5,Packages,develop,"macOS, CentOS, SuSE, Windows Subsystem for Linux (WSL)",10 - 100,"2.7, 3.6, 3.7",Do it!,Do it!,spack load,Module generation,"AMD, Intel, IBM Power","NVIDIA, AMD","gcc, Intel Compilers, NVIDIA Compilers (new PGI), LLVM",Somewhat important,Very Important,Slightly Important,Slightly Important,Somewhat important,Somewhat important,Somewhat important,Somewhat important,Very Important,Slightly Important,Somewhat important,Slightly Important,Speed!,Maybe,No,Documentation,Monthly,Probably,Good,Good,OK,OK,"Maintaining some Spack packages, installing various packages (MPI etc.) on my computer zoo",,,,Cupti? Could become part of CudaPackage.,"TBH, I'm not sure what half of the present / future Spack features mentioned in this survey are. I need to catch up on the documentation!"
11/17/2020 21:17:45,Software Developer,Company,United States,No,Embedded Systems,Tutorial,0,"Packages, Slack Discussions, Issues",0.15,"Ubuntu, Debian, Fedora",100 - 200,3.5,Do it!,I'd live (I can provide Python 3 somehow),"spack load, Spack environments","Environments, Stacks (matrices in environments), Binary Caches, build-env (debug a build), Python extensions (link python packages into interpreter prefix), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, ARM","NVIDIA, AMD, Intel","gcc, LLVM",Somewhat important,Somewhat important,Somewhat important,Somewhat important,Very Important,Critical,Critical,Critical,Somewhat important,Somewhat important,Somewhat important,Somewhat important,A tutorial using spack to bootstrap linux distribution from scratch,"Yes, I'd attend",Yes,"Documentation, Slack",Weekly,"Yes, definitely!",Good,Excellent,Good,Good,Develop software that requires lots of moving deps and apt is not sufficient,"Reproducible Build Environment, Easy/Automated dependency upgrade, Clear Error Message",Dont know which features can be used. Understand various environment variables that affects the build system.,"An example of packaging environment, building a big project with lots of dependencies, and then package that software using spack features","pyinstaller, z3, libgc, grpcio",Great Jobs! Please continue the effort!
11/17/2020 21:18:21,Scientist/Researcher,Other Public Research Lab,Italy,No,Traditional HPC / Simulation,Word of mouth,2,Packages,0.15,"CentOS, Arch, Windows Subsystem for Linux (WSL)",200 - 500,"3.6, 3.8",Do it!,Do it!,"spack load, Spack environments, Environment Modules (TCL modules)","Environments, Module generation, build-env (debug a build), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel","NVIDIA, AMD","gcc, Intel Compilers, LLVM, AMD aocc, nvcc",Somewhat important,Very Important,Very Important,Slightly Important,Very Important,Critical,Very Important,Very Important,Slightly Important,Not Important,Very Important,Not Important,"Better environments that can be used do have a set of basic tools (cmake, compilers, git, etc.) to use as development environment. Something like multiple or joined environments.","Yes, I'd attend",Yes,"Documentation, Mailing List",Weekly,Probably not,Excellent,Excellent,Good,Excellent,"traditional HPC workflow. would like to use environments but they do not fit my use case yet, so still relying on env-modules and spack load",interoperability between different platforms,graphical stack,better usage of system packages,"code_saturne, metview (I hope to contribute these soon)",
11/17/2020 21:57:12,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,Traditional HPC / Simulation,Used at my site,0,No,develop,"TOSS, Red Hat",1 - 10,"2.7, 3.6",I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),Lmod,Environments,"AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), LLVM, AMD hipclang, nvcc, XL, CCE (Cray Compilers), armclang",Slightly Important,Somewhat important,Slightly Important,Slightly Important,Critical,Critical,Somewhat important,Very Important,Critical,Somewhat important,Critical,Not Important,"Documentation, Example coding for all DOE HPC computers and compiler combinations and for complicated projects.  Examples of how to provide custom dependencies and actions not detectable with existing compiler dependency rules.

 For instance. The make process may automatically  codegenerated based on another file.  Imagine a 'yaml' type file (but it could be some other type file) is used by a project script to generate .c and .h files, possibly over-writing existing files by design.  If this yaml is updated, then the script needs to be run to re-generate the source files and then recompile them by the 'make' process.

Or imagine that a project provides scripts which scans XML files, which are then processed to create .c and .h files which do not live in a repository, they only exist in the build space.  If the XML files are updated the genreation of the source needs to happen, then this trigger a recompile.",Maybe,No,Coworkers,Monthly,Probably not,OK,OK,OK,OK,"I have multiple libraries I maintain. I build at multiple sites, with multiple compilers and multiple configuration options (MPI, OpenMP, GPU, etc.)","Uniform configuration of multiple projects across multiple compilers, multiple computers and multiple sites.",,Great examples on how to use Spack  with a new project.,,
11/17/2020 21:19:41,Scientist/Researcher,University HPC/Computing Center,Japan,No,Traditional HPC / Simulation,Tutorial,0,No,0.15,"CentOS, Ubuntu",10 - 100,"3.7, 3.8",Do it!,Do it!,spack load,"spack external find, Externals in packages.yaml","AMD, Intel","NVIDIA, AMD","gcc, Intel Compilers, AMD aocc, nvcc",Somewhat important,Critical,Critical,Not Important,Critical,Critical,Critical,Critical,Very Important,Not Important,Critical,Not Important,"Better implementation  for loading packages that involves sourcing bash scripts such as intel parallel studio packages, openfoam","Yes, I'd attend",No,"Documentation, Mailing List",Weekly,Probably not,Good,Good,Good,Excellent,,,,,,
11/17/2020 21:20:20,Scientist/Researcher,DOE/Office of Science Lab (ORNL/ANL/LBL),United Kingdom,Yes,Computer Science Research,Word of mouth,4,"Packages, Slack Discussions, Issues",develop,"Debian, SuSE","> 1,000","2.7, 3.6, 3.7",Do it!,I'd live (I can provide Python 3 somehow),Spack environments,Environments,Intel,NVIDIA,"gcc, LLVM",Somewhat important,Very Important,Slightly Important,Not Important,Not Important,Very Important,Very Important,Somewhat important,Not Important,Not Important,Somewhat important,Not Important,,"Yes, I'd attend",No,"Documentation, Slack, Coworkers",Weekly,Probably not,Good,Excellent,Good,Good,,Being able to rebuild my entire development stack in a couple of commands.,Uninstalling an environment should be easier; spack could also help tracking which installed packages are part of an environment (and which one).,Tutorials on how to leverage spack to enable reproducible experiments.,,
11/17/2020 21:21:23,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,"Traditional HPC / Simulation, Computer Science Research",Word of mouth,3,"Packages, Slack Discussions, Mailing List","0.15, develop","macOS, Red Hat, CentOS, Ubuntu",100 - 200,"2.7, 3.8",Do it!,Do it!,spack load,"Environments, Module generation, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, NVIDIA Compilers (new PGI), LLVM, AMD hipclang, nvcc, XL, CCE (Cray Compilers), armclang",Somewhat important,Very Important,Slightly Important,Slightly Important,Slightly Important,Somewhat important,Slightly Important,Slightly Important,Very Important,Not Important,Not Important,Slightly Important,"Git integration, any feature that supports monorepo->polyrepo transition","Yes, I'd present something!",No,Slack,Monthly,Probably,OK,OK,OK,OK,,Standardized way of connecting variants/features with build rules,"We have compilers that depend on using Clang with specific GCC versions. There is no way to specify a compiler as %clang%gcc@7.4.0, e.g.","Make Spack more useful for development, not just deployment",,
11/17/2020 21:22:05,Scientist/Researcher,Private Research Lab,United States,Yes,Traditional HPC / Simulation,Birds-of-a-feather (BOF) at conference,3,No,"0.15, develop","macOS, CentOS, Ubuntu",1 - 10,"3.6, 3.7",Do it!,Do it!,"spack load, Spack environments","Environments, build-env (debug a build), spack external find","AMD, Intel","NVIDIA, AMD","gcc, Intel Compilers, LLVM, AMD hipclang, nvcc",Critical,Very Important,Very Important,Slightly Important,Slightly Important,Critical,Somewhat important,Slightly Important,Critical,Not Important,Critical,Somewhat important,,"Yes, I'd attend",No,"Documentation, Slack",Monthly,No,Good,Excellent,Good,Good,Handle the dependencies of my own development code not in spack.,Variants,,I think most of my issues are on your roadmap for being fixed.,,
11/17/2020 21:22:54,Software Developer,University HPC/Computing Center,United States,No,"Traditional HPC / Simulation, AI/ML",Word of mouth,2,"Packages, Core Features, Slack Discussions, Issues",develop,"Red Hat, CentOS",10 - 100,"2.7, 3.8",Do it!,Do it!,"spack load, Spack environments, Environment Modules (TCL modules)","Environments, Module generation, spack-python (Python scripting), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, Intel Compilers, LLVM, AMD hipclang, nvcc",Critical,Somewhat important,Somewhat important,Slightly Important,Somewhat important,Somewhat important,Somewhat important,Very Important,Critical,Somewhat important,Somewhat important,Slightly Important,,"Yes, I'd attend",No,"Documentation, Slack, Coworkers",Monthly,Probably not,Good,Excellent,Good,Good,,The community,,,,
11/17/2020 21:23:40,Scientist/Researcher,University HPC/Computing Center,Switzerland,No,Traditional HPC / Simulation,Word of mouth,1,No,develop,Ubuntu,10 - 100,3.8,Do it!,Do it!,spack load,Environments,"AMD, Intel, ARM","NVIDIA, AMD","gcc, LLVM, nvcc, CCE (Cray Compilers)",Somewhat important,Critical,Somewhat important,Somewhat important,Very Important,Somewhat important,Very Important,Very Important,Critical,Very Important,Very Important,Somewhat important,,Maybe,Yes,"Documentation, Slack, Coworkers",Monthly,Probably not,OK,OK,OK,Good,"I use spack install and spack load xxx, it works. I'm happy.",it's easy to edit packages via the python thingy,,stop it reinstalling 25 copies of the same library when they are all the same but with a different hash (why?),,"Some multiple choice questions needed an answer ""I have no idea because I'm not a power user, so I don't really know if I need concretization of XXX since I have o idea what it is"""
11/17/2020 21:24:15,Software Developer,University HPC/Computing Center,United States,Yes,Computer Science Research,Word of mouth,3,"Packages, Slack Discussions, Mailing List, Issues","0.14, 0.15, develop","Red Hat, CentOS, Ubuntu",10 - 100,"2.7, 3.6, 3.7",I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),"spack load, Spack environments, Lmod, Environment Modules (TCL modules)","Environments, Module generation, Stacks (matrices in environments), Binary Caches, spack ci (generate GitLab Pipelines)","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), LLVM, AMD aocc, AMD hipclang, nvcc, XL, CCE (Cray Compilers), Fujitsu Compilers, armclang",Critical,Very Important,Very Important,Slightly Important,Very Important,Very Important,Very Important,Very Important,Somewhat important,Slightly Important,Very Important,Slightly Important,"spack recommend spec - that recommends the list of variants that should be used based on what compilers are already installed and what packages are configured in a mirror, so Spack doesn’t build all the dependencies! ","Yes, I'd attend",Yes,Coworkers,Weekly,Probably not,OK,Good,Good,Good,,Build cache. ,Concretizer that forces rebuild of commonly used packages. ,Concretizer.,"OneAPI, TensorFlow optimized for GPUs",
11/17/2020 21:25:16,System Administrator,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,Traditional HPC / Simulation,Used at my site,2,"Core Features, Slack Discussions, Issues","0.15, develop","Red Hat, SuSE",200 - 500,"3.6, 3.7, 3.8",Do it!,Do it!,"spack load, Environment Modules (TCL modules), spack view","Environments, Module generation, Binary Caches, build-env (debug a build), Externals in packages.yaml, Concretization preferences in packages.yaml, spack ci (generate GitLab Pipelines)",Intel,Intel,"gcc, Intel Compilers, Intel OneAPI / dpc++, LLVM, CCE (Cray Compilers)",Very Important,Slightly Important,Somewhat important,Not Important,Slightly Important,Slightly Important,Not Important,Somewhat important,Slightly Important,Not Important,Very Important,Not Important,,"Yes, I'd present something!",Yes,"Documentation, Slack",Daily,Probably not,Excellent,Excellent,Good,Good,"We're mandated under ECP to implement spack at our facility, and are taking the opportunity to evaluate it's effectiveness for deployment as a supplement and possible alternative to Cray's PE.",it's often the fastest and easiest way to full a request for an updated package,The overall complexity of spack,"Advanced tutorials, by topic/use case.",,I really enjoy working with the spack team.
11/17/2020 21:25:57,Software Developer,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,No,High Energy Physics,Word of mouth,3,"Packages, Core Features, Documentation, Slack Discussions, Mailing List, Issues",develop,"macOS, Red Hat, CentOS, Ubuntu",100 - 200,"2.7, 3.7, 3.8",Do it!,I'd live (I can provide Python 3 somehow),"spack load, Spack environments","Environments, Module generation, Chaining, Stacks (matrices in environments), Binary Caches, Command Extensions, Python extensions (link python packages into interpreter prefix), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power",NVIDIA,"gcc, LLVM",Critical,Very Important,Critical,Not Important,Very Important,Critical,Somewhat important,Very Important,Critical,Somewhat important,Very Important,Not Important,Installation of specific packages / dependency branches from concretized YAML,"Yes, I'd attend",No,"Documentation, Slack, Mailing List, Coworkers",Daily,Probably not,Good,Excellent,Good,Good,Coherent release production and management; multi-package development by non-expert developers; multi-site installation of binary packages.,"Responsiveness of developers to questions, ideas, contributions.",Insuffiently performant / flexible concretizer.,Fully-working backtracking concretizer,,
11/17/2020 21:26:42,System Administrator,University HPC/Computing Center,United States,No,"Traditional HPC / Simulation, Statistics / Data Analysis, AI/ML, Bioinformatics, High Energy Physics",Search,4,"Packages, Core Features, Documentation, Slack Discussions, Mailing List, Issues",develop,CentOS,"> 1,000",2.7,Do it!,I'd live (I can provide Python 3 somehow),Lmod,"Environments, Module generation, Stacks (matrices in environments), build-env (debug a build), Python extensions (link python packages into interpreter prefix), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, Intel Compilers, Intel OneAPI / dpc++, NVIDIA Compilers (new PGI), nvcc",Somewhat important,Very Important,Somewhat important,Somewhat important,Slightly Important,Slightly Important,Slightly Important,Slightly Important,Slightly Important,Slightly Important,Somewhat important,Not Important,Having environments be part of stacks.,Maybe,Yes,"Documentation, Slack, Mailing List",Weekly,Probably not,Good,Good,OK,Good,,"compiler optimizations, module generation",slowness; things not working as documented or expected,speed up extension activation,,
11/17/2020 21:27:19,User Support Staff,University HPC/Computing Center,United States,No,"Traditional HPC / Simulation, Statistics / Data Analysis, AI/ML, Bioinformatics",Tutorial,0,"Slack Discussions, Issues",0.15,CentOS,200 - 500,"2.7, 3.8",Do it!,I'd live (I can provide Python 3 somehow),Lmod,"Module generation, Stacks (matrices in environments), spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,"gcc, Intel Compilers, NVIDIA Compilers (new PGI), LLVM, nvcc",Critical,Critical,Critical,Not Important,Very Important,Somewhat important,Very Important,Very Important,Somewhat important,Very Important,Very Important,Slightly Important,Upgrade specific package recipes without upgrading the entire repo,"Yes, I'd attend",Yes,"Documentation, Slack",Daily,No,Good,Good,Good,Good,Providing scientific software stack for a large heterogeneous cluster,"Software Installation, Standardization, Automation","External Packages, TCL Modulefile generation, Concretization, Variant Handling, Obscure Scientific Software Recipes",Concretization issues,"ANSYS, ABAQUS, COMSOL","Yes, I like spack, can't do without it now."
11/17/2020 21:27:57,User Support Staff,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,"Statistics / Data Analysis, Bioinformatics",Word of mouth,3,No,0.15,"macOS, CentOS, SuSE",1 - 10,"3.7, 3.8",Do it!,Do it!,"spack load, Lmod","Module generation, spack external find","AMD, Intel",NVIDIA,gcc,Slightly Important,Somewhat important,Not Important,Somewhat important,Somewhat important,Somewhat important,Not Important,Slightly Important,Slightly Important,Slightly Important,Slightly Important,Not Important,"Improve documentation, especially for getting started and best practices for using built artifacts. ","Yes, I'd attend",Yes,"Documentation, Slack",Daily,Probably not,Bad,Good,OK,OK,Module building for HPC. Typical workflow is 'spack find' and hope there is already a package. ,,I have tried getting going with spack a number of times over the past several years. My initial efforts hit a roadblock in figuring out a good way of using built artifacts. More recently python errors have prevented builds from completing.,,,
11/17/2020 21:28:36,User Support Staff,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,No,High Energy Physics,Used at my site,1,Packages,"0.12, 0.14",CentOS,1 - 10,3.7,Do it!,Do it!,spack load,"Environments, Binary Caches, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel",NVIDIA,gcc,Slightly Important,Somewhat important,Slightly Important,Somewhat important,Somewhat important,Very Important,Somewhat important,Slightly Important,Slightly Important,Slightly Important,Somewhat important,Not Important,faster concretizer,Maybe,Yes,"Documentation, Slack, Coworkers",Weekly,Probably not,Good,Excellent,Good,Good,,,,,,
11/17/2020 21:29:14,User Support Staff,Other Public Research Lab,Japan,No,Traditional HPC / Simulation,Used at my site,0,Packages,"0.15, develop","Red Hat, CentOS",10 - 100,"2.7, 3.6",Do it!,Do it!,spack load,"Environments, Module generation, Chaining","AMD, Intel, ARM",NVIDIA,"gcc, Fujitsu Compilers",Slightly Important,Somewhat important,Slightly Important,Slightly Important,Slightly Important,Slightly Important,Somewhat important,Very Important,Very Important,Very Important,Very Important,Slightly Important,,Maybe,Yes,"Documentation, Slack",Weekly,Probably not,Good,Good,Good,Excellent,,,,,,
11/17/2020 21:30:22,User Support Staff,Company,United States,Yes,Traditional HPC / Simulation,Word of mouth,0,No,0.15,Red Hat,1 - 10,"2.7, 3.7, 3.8",Do it!,Do it!,Environment Modules (TCL modules),"Environments, Module generation, spack external find, Externals in packages.yaml","AMD, Intel, ARM",AMD,"gcc, CCE (Cray Compilers)",Not Important,Very Important,Slightly Important,Not Important,Not Important,Very Important,Slightly Important,Not Important,Slightly Important,Not Important,Slightly Important,Not Important,Better spack error handling. As in: 'why didn't this work?',"Yes, I'd attend",No,"Documentation, Slack, Coworkers",Daily,Probably not,Good,Excellent,Good,OK,Just started slack. So building specific packages using spack.,Building something that has lots' of dependencies. Spack is really usefull in building those dependices. ,When something goes wrong what happend? Complicated to use. Needs more Cray support .,Improved cray support. Better slack 'error handling',,I have only been using spack for about a month. There are lots of details to pick up. The slack channel is a really big help. Also the documentation is pretty good.  Personally I have issues with slack with multiple things are broken.
11/17/2020 21:31:14,Manager,Other Public Research Lab,Switzerland,No,"Traditional HPC / Simulation, Statistics / Data Analysis, Computer Science Research",Used at my site,1,No,0.15,SuSE,1 - 10,2.7,I'd live.  (I can provide 2.7 somehow),Do it!,Environment Modules (TCL modules),"spack containerize, Binary Caches, spack ci (generate GitLab Pipelines)","AMD, Intel",NVIDIA,"gcc, Intel Compilers, PGI, NVIDIA Compilers (new PGI), AMD aocc, nvcc",Somewhat important,Very Important,Somewhat important,Slightly Important,Very Important,Very Important,Very Important,Very Important,Very Important,Critical,Very Important,Slightly Important,,"Yes, I'd attend",Yes,"Documentation, Slack",Monthly,"Yes, definitely!",Good,Good,OK,Good,"Using Spack to build complex applications natively. Moving the the build into containers, if possible with Spack containerize.",Installing difficult software,failing to build even though the recipe was supposed to work,Ability to support feature change requests more actively.,"rather than key packages, reproducibility is crucial.",Thanks for the good work and dedicated support!
11/17/2020 21:31:53,All of the Above,Company,United Kingdom,No,Traditional HPC / Simulation,Word of mouth,0,Issues,develop,CentOS,10 - 100,3.7,Do it!,I'd live (I can provide Python 3 somehow),"spack load, Lmod, Environment Modules (TCL modules)","Module generation, Externals in packages.yaml","AMD, Intel",Intel,"gcc, Intel Compilers",Very Important,Very Important,Not Important,Not Important,Not Important,Not Important,Somewhat important,Critical,Not Important,Slightly Important,Not Important,Not Important,,Maybe,Yes,"Documentation, Slack",Weekly,Probably not,Bad,Excellent,Bad,Good,Installing HPC s/w not as root to test compiler/mpi toolchains/interconnect performance differences,,"- https://github.com/spack/spack/issues/16730
- https://github.com/spack/spack/issues/17791",Make the docs accurate for Lmod setup. Fix the problems with MKL/BLAS libraries in dependencies,WRF but I know this is hard!,
11/17/2020 21:32:36,Scientist/Researcher,Other Public Research Lab,Germany,No,Traditional HPC / Simulation,Word of mouth,0,No,0.15,"Red Hat, CentOS, Ubuntu",1 - 10,3.7,I'd live.  (I can provide 2.7 somehow),Do it!,"Spack environments, Lmod, Environment Modules (TCL modules)","Environments, Module generation, Chaining, Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, ARM",NVIDIA,"gcc, Intel Compilers, NVIDIA Compilers (new PGI), nvcc, XL, armclang",Somewhat important,Very Important,Somewhat important,Not Important,Not Important,Very Important,Very Important,Somewhat important,Somewhat important,Not Important,Very Important,Not Important,,"Yes, I'd attend",No,"Documentation, Slack, Coworkers",Weekly,Probably,OK,Good,Excellent,Excellent,,,,,,
11/17/2020 21:33:11,Scientist/Researcher,Company,United States,No,Traditional HPC / Simulation,Word of mouth,1,No,develop,"macOS, CentOS, Ubuntu, Debian, Amazon Linux",100 - 200,"2.7, 3.5, 3.6, 3.7",Do it!,I'd live (I can provide Python 3 somehow),"spack load, Spack environments, Environment Modules (TCL modules)","Environments, Module generation, spack external find, Externals in packages.yaml","AMD, Intel, ARM","NVIDIA, AMD","gcc, Intel Compilers, NVIDIA Compilers (new PGI), LLVM, AMD aocc, nvcc, NAG, armclang",Slightly Important,Somewhat important,Slightly Important,Somewhat important,Slightly Important,Slightly Important,Not Important,Very Important,Very Important,Not Important,Very Important,Not Important,List what packages have been loaded already via `spack load`,"Yes, I'd attend",Yes,Documentation,Weekly,Probably not,Excellent,Good,Good,Excellent,Building benchmarks,Dependency management and compiler integration,,,,
11/17/2020 21:33:48,Software Developer,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,Traditional HPC / Simulation,Presentation,0,No,"0.12, 0.10","macOS, CentOS, Ubuntu",1 - 10,2.7,Do it!,I'd live (I can provide Python 3 somehow),"spack load, Spack environments",Environments,"AMD, Intel","NVIDIA, AMD, Intel","gcc, Intel Compilers, NVIDIA Compilers (new PGI), nvcc",Not Important,Somewhat important,Slightly Important,Not Important,Slightly Important,Somewhat important,Slightly Important,Slightly Important,Somewhat important,Not Important,Somewhat important,Not Important,glossary of terms,No,No,Documentation,Yearly,No,Bad,OK,OK,OK,,,,,,
11/17/2020 22:15:07,Scientist/Researcher,University HPC/Computing Center,United States,Yes,Traditional HPC / Simulation,Word of mouth,0,"Packages, Slack Discussions","0.14, 0.15","macOS, Red Hat, Ubuntu",100 - 200,3.7,Do it!,Do it!,"spack load, spack setup","Environments, build-env (debug a build), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power","NVIDIA, AMD, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, PGI, NVIDIA Compilers (new PGI), LLVM, AMD hipclang, nvcc, XL, CCE (Cray Compilers)",Very Important,Very Important,Very Important,Not Important,Not Important,Very Important,Somewhat important,Slightly Important,Slightly Important,Not Important,Not Important,Not Important,"Better support cmake (ie, `spack setup` without requiring additional environment modifications, wrapped compilers etc)",Maybe,No,"Documentation, Slack, Source Code",Weekly,No,Good,OK,OK,OK,"I'm developing science codes. Spack is good for installing dependencies, but it's less targeted at a developer workflow, ie, frequent rebuilds that I trigger myself. `spack dev-build` is awkward to use for everyday use, and `spack setup` is deprecated and has some problems, but still my preferred option. Setting up an environment independently of what I already set up in my package.py file leads to duplication and inconsistencies.",,"A lot of the time, something doesn't work out of the box. That includes problems in packages, as well as the concretizer not solving solvable configurations (e.g., one package depends on hwloc, which makes it default to current 2.x, the other depends on < 2.0 -> error). python2 and python3 in the same (actual or bundle-) package is not possible.
In addition, spack unnecessarily reinstalls stuff that doesn't actually need redoing. Making cmake 3.17.4 available means everything previous installed with cmake 3.17.3 will now be rebuilt.","Besides the pain points above, support for additional repos (e.g. directly via github url). More generally, it'd be nice to separate the package repos from the rest of spack's development.",,"While I clearly have some criticism, I do consider spack to be a rather valuable tool, even more so if I could get more collaborators to use it, too."
11/17/2020 22:12:20,Software Developer,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,Traditional HPC / Simulation,Tutorial,2,Packages,0.13,Red Hat,1 - 10,2.7,I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),Environment Modules (TCL modules),"Environments, Module generation, spack containerize, build-env (debug a build), Externals in packages.yaml, Concretization preferences in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD, Intel","gcc, Intel Compilers, NVIDIA Compilers (new PGI), nvcc, XL, CCE (Cray Compilers)",Slightly Important,Very Important,Critical,Not Important,Slightly Important,Not Important,Not Important,Somewhat important,Slightly Important,Not Important,Very Important,Somewhat important,"Avoid having to rebuild and install packages like cmake, python, perl, ninja, etc. for every compliler.",Maybe,Yes,"Documentation, Slack, Email",Weekly,No,OK,OK,Bad,Bad,"We want to be able to install a stack of software stating with compilers and MPI on some systems (and using pre-installed compilers and MPI on other systems) and then installing tools like CMake, Python, and Pearl and then a bunch of libraries with and without MPI for many different permutations of compilers and MPI and versions.   And for there to be logically named environment modules for those packages.",The hope that it will address our use cases in the future more seamlessly.,"Build failures for obscure packages Spack is trying to build that are already installed on most Linux distributions; struggling to get spack to build just one version of BLAS, MPI; avoid rebuilding and installing packages like CMake, Python, Pearl, Ninja, etc. over and over again for every compiler; better support Clang + gfortran compiler sets; don't write into home directory; make state more obvious; make it easier to produce the modules with the names that you want and make sense, don't even try to go out to the internet to get source if I am providing a source repository of tarballs.  I actually failed to be able to get Spack to work for our use cases after months of work.",Improve basic robustness of cloning and running Spack to build a known good set of versions of common HPC packages on many platforms.,,Focus on basic stability and robustness before spending lots of time on fancy features that may projects don't need.
11/17/2020 21:35:54,Scientist/Researcher,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,Computer Science Research,Presentation,2,Issues,"0.14, 0.15",macOS,10 - 100,3.7,I'd live.  (I can provide 2.7 somehow),I'd live (I can provide Python 3 somehow),"Lmod, Environment Modules (TCL modules)","Module generation, build-env (debug a build), Externals in packages.yaml","AMD, Intel, IBM Power, ARM","NVIDIA, AMD","gcc, Intel Compilers, PGI, LLVM, nvcc, XL",Somewhat important,Slightly Important,Somewhat important,Slightly Important,Somewhat important,Somewhat important,Slightly Important,Slightly Important,Somewhat important,Slightly Important,Somewhat important,Slightly Important,,"Yes, I'd attend",No,"Documentation, Slack",Monthly,Probably not,Good,Good,OK,Good,,,,,,
11/17/2020 21:36:32,Scientist/Researcher,"DOE/NNSA Lab (e.g., LLNL/LANL/SNL)",United States,Yes,Traditional HPC / Simulation,Word of mouth,1,"Packages, Slack Discussions","0.14, 0.15","macOS, Red Hat, SuSE","> 1,000",3.8,Do it!,Do it!,"Lmod, Environment Modules (TCL modules)","Environments, Module generation, Chaining, Stacks (matrices in environments), Binary Caches, spack-python (Python scripting), Externals in packages.yaml, spack ci (generate GitLab Pipelines)","Intel, IBM Power, ARM",NVIDIA,"gcc, Intel Compilers",Critical,Critical,Slightly Important,Not Important,Somewhat important,Slightly Important,Not Important,Somewhat important,Somewhat important,Very Important,Very Important,Not Important,"Improved concretizer for better dependency graph, parallel builds","Yes, I'd attend",Yes,"Documentation, Coworkers",Daily,Probably not,Good,Good,Good,Good,"Distributed build system with Spack environments, spack mirror creation, spack install, spack buildcache create, spack buildcache install, Python scripting",Build instructions for every package I've ever needed,"parallelism, determining the optimal dependency+variant combination to reduce build size",concretizer,,Keep up the great work.
11/17/2020 21:37:13,User Support Staff,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,"Traditional HPC / Simulation, Statistics / Data Analysis, AI/ML, Computer Science Research, Bioinformatics, High Energy Physics, Compiler Testing",Word of mouth,2,"Packages, Documentation, Slack Discussions","0.14, 0.15, develop",SuSE,100 - 200,"3.6, 3.7",Do it!,Do it!,Environment Modules (TCL modules),"Environments, Module generation, spack ci (generate GitLab Pipelines)","AMD, Intel","NVIDIA, Intel","gcc, Intel Compilers, Intel OneAPI / dpc++, NVIDIA Compilers (new PGI), LLVM, CCE (Cray Compilers)",Very Important,Critical,Slightly Important,Slightly Important,Somewhat important,Slightly Important,Somewhat important,Critical,Somewhat important,Very Important,Somewhat important,Not Important,Automate module load testing using Lmodule http://lmodule.rtfd.io/,"Yes, I'd attend",Yes,"Documentation, Slack",Daily,Probably not,Excellent,Excellent,Good,Good,Install E4S stack  at the DOE facilities,Automate software build & install process for HPC cluster. ,"Output of spack concretize (https://github.com/spack/spack/issues/18588), The spack configuration scopes are confusing when troubleshooting issues the command like spack config blame config is useful when troubleshooting, however i would like to see all spack configuration moving towards spack environment file (spack.yaml) this simplifies the process. ","Build lots of buildcaches for each site to speed up builds. It could be nice to have a cloud repository could be AWS, GCP, where spack host all the buildcaches. The buildcaches can be generic for target architectures (x86_64, ppc64) for os (rhel, centos, ubuntu). If other facilities want to share buildcache we can have a separate repository to host facility specific build-caches.

If sites update the buildcache (i.e add new packages) there should be a spack command to allow user to register and update the buildcache on the cloud. The users would benefit from the build cache and other sites could leverage other sites buildcache to build software. ",,
11/17/2020 21:37:52,Software Developer,DOE/Office of Science Lab (ORNL/ANL/LBL),United States,Yes,Bioinformatics,Used at my site,1,No,0.15,"macOS, Red Hat, CentOS, Ubuntu, Debian, Amazon Linux",1 - 10,3.7,Do it!,Do it!,Environment Modules (TCL modules),Module generation,"AMD, Intel, IBM Power","NVIDIA, AMD, Intel","gcc, Intel Compilers, NVIDIA Compilers (new PGI), LLVM",Not Important,Very Important,Slightly Important,Somewhat important,Critical,Very Important,Somewhat important,Very Important,Very Important,Not Important,Very Important,Not Important,better hpc support,Maybe,Yes,Documentation,Yearly,Probably not,OK,OK,OK,OK,,,,,,
11/18/2020 9:15:39,System Administrator,University HPC/Computing Center,United States,No,"Traditional HPC / Simulation, Statistics / Data Analysis, AI/ML, Computer Science Research, Bioinformatics, High Energy Physics, Compiler Testing, Visualization",Birds-of-a-feather (BOF) at conference,2,"No, Slack Discussions","0.15",CentOS,1 - 10,2.7,Do it!,I'd live (I can provide Python 3 somehow),Lmod,"Module generation, spack external find, Externals in packages.yaml, Concretization preferences in packages.yaml",Intel,NVIDIA,"gcc, Intel Compilers, LLVM, nvcc",Somewhat important,Critical,Somewhat important,Not Important,Slightly Important,Slightly Important,Slightly Important,Somewhat important,Very Important,Very Important,Very Important,Not Important,,"Yes, I'd attend",Yes,"Documentation, Slack, Mailing List, GitHub, spack help",Monthly,Probably not,Good,OK,OK,Good,Replacing manual/scripted builds of HPC software and the generation of the associated modules in a hierarchical Lmod (Core/Compiler/MPI/CUDA).,Less figuring out how to build things.,"I don't actually use Spack in production for the reason above. I've run into problems, for example, building Singularity dependencies, when I actually have it installed manually already and have no issues. This is much much better in 0.15.x. I'm just trying 0.16.x now, so I'm assuming it will continue to improve.","I've attempted to do installs of software I've already installed (and therefore have all of the dependencies) and it's wanted to install 25+ dependencies, many of which have their own dependencies. When you have builds that are 25-50 deep, the chances of success are really low. That's got to stop. I know work is going on here and it's gotten better.",,
